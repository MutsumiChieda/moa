{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:37: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../script/')\n",
    "from train import run_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 7),\n",
    "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 2048),\n",
    "        \"dropout\": trial.suggest_uniform(\"dropout\", 0.1, 0.8),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-3),\n",
    "    }\n",
    "    loss_all = []\n",
    "    for fold_ in range(5):\n",
    "        loss_tmp = run_training(fold_, params, save_model=False)\n",
    "        loss_all.append(loss_tmp)\n",
    "    return np.mean(loss_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "epoch=   0, train_loss=0.74553, valid_loss=0.71539, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73723, valid_loss=0.71326, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.73249, valid_loss=0.70960, patience=  0/ 10\n",
      "fold=0, best vallidation loss=0.7095972061157226\n",
      "\n",
      "[Fold No. 1]\n",
      "epoch=   0, train_loss=0.74517, valid_loss=0.71648, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73676, valid_loss=0.71343, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.73160, valid_loss=0.70923, patience=  0/ 10\n",
      "fold=1, best vallidation loss=0.7092270135879517\n",
      "\n",
      "[Fold No. 2]\n",
      "epoch=   0, train_loss=0.74466, valid_loss=0.71399, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73621, valid_loss=0.71199, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.73148, valid_loss=0.70832, patience=  0/ 10\n",
      "fold=2, best vallidation loss=0.7083248138427735\n",
      "\n",
      "[Fold No. 3]\n",
      "epoch=   0, train_loss=0.74567, valid_loss=0.71585, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73797, valid_loss=0.71354, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.73277, valid_loss=0.70990, patience=  0/ 10\n",
      "fold=3, best vallidation loss=0.7099024772644043\n",
      "\n",
      "[Fold No. 4]\n",
      "epoch=   0, train_loss=0.74684, valid_loss=0.71718, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73811, valid_loss=0.71439, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.73289, valid_loss=0.71062, patience=  0/ 10\n",
      "fold=4, best vallidation loss=0.7106162548065186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-20 14:07:06,542] Trial 0 finished with value: 0.7095335531234741 and parameters: {'num_layers': 1, 'hidden_size': 851, 'dropout': 0.3855954879404613, 'learning_rate': 1.678454544241825e-05}. Best is trial 0 with value: 0.7095335531234741.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "epoch=   0, train_loss=0.74687, valid_loss=0.69347, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73239, valid_loss=0.69190, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72222, valid_loss=0.68992, patience=  0/ 10\n",
      "fold=0, best vallidation loss=0.6899198055267334\n",
      "\n",
      "[Fold No. 1]\n",
      "epoch=   0, train_loss=0.74701, valid_loss=0.69327, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73223, valid_loss=0.69145, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72200, valid_loss=0.68967, patience=  0/ 10\n",
      "fold=1, best vallidation loss=0.6896729350090027\n",
      "\n",
      "[Fold No. 2]\n",
      "epoch=   0, train_loss=0.74667, valid_loss=0.69287, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73149, valid_loss=0.69193, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72067, valid_loss=0.68992, patience=  0/ 10\n",
      "fold=2, best vallidation loss=0.6899202585220336\n",
      "\n",
      "[Fold No. 3]\n",
      "epoch=   0, train_loss=0.74686, valid_loss=0.69295, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73218, valid_loss=0.69117, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72149, valid_loss=0.68931, patience=  0/ 10\n",
      "fold=3, best vallidation loss=0.6893128871917724\n",
      "\n",
      "[Fold No. 4]\n",
      "epoch=   0, train_loss=0.74610, valid_loss=0.69291, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73088, valid_loss=0.69168, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72047, valid_loss=0.68931, patience=  0/ 10\n",
      "fold=4, best vallidation loss=0.6893082737922669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-20 14:12:33,021] Trial 1 finished with value: 0.6896268320083617 and parameters: {'num_layers': 5, 'hidden_size': 1075, 'dropout': 0.4109948740892778, 'learning_rate': 5.455291352461367e-05}. Best is trial 1 with value: 0.6896268320083617.\n"
     ]
    }
   ],
   "source": [
    "partial_obj = partial(objective)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(partial_obj, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 0.6896268320083617\n",
      "Params: \n",
      "{'num_layers': 5, 'hidden_size': 1075, 'dropout': 0.4109948740892778, 'learning_rate': 5.455291352461367e-05}\n",
      "\n",
      "[Fold No. 0]\n",
      "epoch=   0, train_loss=0.74700, valid_loss=0.69378, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73228, valid_loss=0.69209, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72163, valid_loss=0.69014, patience=  0/ 10\n",
      "fold=0, best vallidation loss=0.6901439666748047\n",
      "\n",
      "[Fold No. 1]\n",
      "epoch=   0, train_loss=0.74644, valid_loss=0.69258, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73201, valid_loss=0.69070, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72129, valid_loss=0.68893, patience=  0/ 10\n",
      "fold=1, best vallidation loss=0.6889344692230225\n",
      "\n",
      "[Fold No. 2]\n",
      "epoch=   0, train_loss=0.74757, valid_loss=0.69424, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73268, valid_loss=0.69276, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72224, valid_loss=0.69083, patience=  0/ 10\n",
      "fold=2, best vallidation loss=0.6908322095870971\n",
      "\n",
      "[Fold No. 3]\n",
      "epoch=   0, train_loss=0.74802, valid_loss=0.69431, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73432, valid_loss=0.69288, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72336, valid_loss=0.69081, patience=  0/ 10\n",
      "fold=3, best vallidation loss=0.6908073186874389\n",
      "\n",
      "[Fold No. 4]\n",
      "epoch=   0, train_loss=0.74702, valid_loss=0.69347, patience=  0/ 10\n",
      "epoch=   1, train_loss=0.73256, valid_loss=0.69171, patience=  0/ 10\n",
      "epoch=   2, train_loss=0.72198, valid_loss=0.69004, patience=  0/ 10\n",
      "fold=4, best vallidation loss=0.6900364875793457\n",
      "OOF Score 0.6901508903503417\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial_ = study.best_trial\n",
    "\n",
    "print(f\"Value: {trial_.value}\")\n",
    "print(\"Params: \")\n",
    "best_params = trial_.params\n",
    "print(best_params)\n",
    "\n",
    "scores = 0\n",
    "for j in range(5):\n",
    "    score = run_training(fold=j, params=best_params, save_model=True)\n",
    "    scores += score\n",
    "print(f\"OOF Score {scores/5}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
