{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:37: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../script/')\n",
    "from os.path import exists\n",
    "import utils\n",
    "import models\n",
    "DEVICE = \"cuda\"\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add folds No. for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fold = \"../input/folds/train_folds.csv\"\n",
    "if not exists(path_fold):\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "    df.loc[:, \"kfold\"] = -1\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    targets = df.drop(\"sig_id\", axis=1).values\n",
    "\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "    for fold_, (tr_, va_) in enumerate(mskf.split(X=df, y=targets)):\n",
    "        df.loc[va_, \"kfold\"] = fold_\n",
    "    df.to_csv(path_fold, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params for training function `run_training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "# optuna 使わないので適当\n",
    "params = {\n",
    "    \"num_layers\": 3,\n",
    "    \"hidden_size\": 16,\n",
    "    \"dropout\": 0.3,\n",
    "    \"learning_rate\": 1e-3,\n",
    "}\n",
    "save_model=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prototyping training process from HERE\n",
    "`run_training` function contains the following code blocks:\n",
    "```python\n",
    "def run_pl_training(fold, params, save_model=False):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "X_train = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "train_targets_scored = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "train_targets_nonscored = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"cp_type\", \"cp_time\", \"cp_dose\"]:\n",
    "    X_train = pd.concat([X_train, pd.get_dummies(X_train[col], prefix=col)], axis=1)\n",
    "    X_test = pd.concat([X_test, pd.get_dummies(X_test[col], prefix=col)], axis=1)\n",
    "X_train = X_train.drop([\"cp_type\", \"cp_time\", \"cp_dose\"], axis=1)\n",
    "X_test = X_test.drop([\"cp_type\", \"cp_time\", \"cp_dose\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=5, weights_summary=\"full\")\n",
    "model = utils.LitMoA(hparams={}, model=models.BaseLine2(879, 206))\n",
    "dm = utils.MoADataModule(hparams={}, data=X_train, targets=train_targets_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "   | Name          | Type              | Params\n",
      "-----------------------------------------------------\n",
      "0  | model         | BaseLine2         | 18 K  \n",
      "1  | model.model   | Sequential        | 18 K  \n",
      "2  | model.model.0 | Linear            | 14 K  \n",
      "3  | model.model.1 | BatchNorm1d       | 32    \n",
      "4  | model.model.2 | Dropout           | 0     \n",
      "5  | model.model.3 | Linear            | 272   \n",
      "6  | model.model.4 | BatchNorm1d       | 32    \n",
      "7  | model.model.5 | Dropout           | 0     \n",
      "8  | model.model.6 | Linear            | 272   \n",
      "9  | model.model.7 | BatchNorm1d       | 32    \n",
      "10 | model.model.8 | Dropout           | 0     \n",
      "11 | model.model.9 | Linear            | 3 K   \n",
      "12 | criterion     | BCEWithLogitsLoss | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  88%|███████████████████████████▏   | 21/24 [00:00<00:00, 33.01it/s, loss=0.727, v_num=7, training_loss=0.716]\n",
      "Epoch 0: 100%|█████████████| 24/24 [00:00<00:00, 34.88it/s, loss=0.727, v_num=7, training_loss=0.716, valid_loss=0.697]\n",
      "Epoch 1:  88%|▉| 21/24 [00:00<00:00, 32.96it/s, loss=0.703, v_num=7, training_loss=0.692, valid_loss=0.697, train_loss=\n",
      "Epoch 1: 100%|█| 24/24 [00:00<00:00, 34.83it/s, loss=0.703, v_num=7, training_loss=0.692, valid_loss=0.677, train_loss=\n",
      "Epoch 2:  88%|▉| 21/24 [00:00<00:00, 33.06it/s, loss=0.680, v_num=7, training_loss=0.67, valid_loss=0.677, train_loss=0\n",
      "Epoch 2: 100%|█| 24/24 [00:00<00:00, 34.93it/s, loss=0.680, v_num=7, training_loss=0.67, valid_loss=0.655, train_loss=0\n",
      "Epoch 3:  88%|▉| 21/24 [00:00<00:00, 31.15it/s, loss=0.653, v_num=7, training_loss=0.634, valid_loss=0.655, train_loss=\n",
      "Epoch 3: 100%|█| 24/24 [00:00<00:00, 33.00it/s, loss=0.653, v_num=7, training_loss=0.634, valid_loss=0.624, train_loss=\n",
      "Epoch 4:  88%|▉| 21/24 [00:00<00:00, 33.17it/s, loss=0.616, v_num=7, training_loss=0.596, valid_loss=0.624, train_loss=\n",
      "Epoch 4: 100%|█| 24/24 [00:00<00:00, 34.98it/s, loss=0.616, v_num=7, training_loss=0.596, valid_loss=0.58, train_loss=0\n",
      "                              \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█| 24/24 [00:00<00:00, 34.77it/s, loss=0.616, v_num=7, training_loss=0.596, valid_loss=0.58, train_loss=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_te = utils.TestMoaDataset(dataset=X_test.iloc[:, 1:].values)\n",
    "loader_te = torch.utils.data.DataLoader(\n",
    "    dataset_te, batch_size=1024, num_workers=0, shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((X_test.shape[0], 206))\n",
    "inference_model = model.model\n",
    "inference_model.eval()\n",
    "for ind, batch in enumerate(loader_te):\n",
    "    p = torch.sigmoid(inference_model(batch[\"x\"])).detach().cpu().numpy()\n",
    "    predictions[ind * 1024 : (ind + 1) * 1024] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make submission template\n",
    "test_features1 = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "s = pd.DataFrame({\"sig_id\": test_features1[\"sig_id\"].values})\n",
    "for col in train_targets_scored.columns[1:].tolist():\n",
    "    s[col] = 0\n",
    "s.loc[:, train_targets_scored.columns[1:]] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess: ctl_vehicle sample has no label\n",
    "s.loc[\n",
    "    s[\"sig_id\"].isin(test_features1.loc[test_features1[\"cp_type\"] == \"ctl_vehicle\", \"sig_id\"]),\n",
    "    train_targets_scored.columns[1:],\n",
    "] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv(\"../submission/submission.csv\", index=False)\n",
    "torch.save(model.model.state_dict(), \"../weight/model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
