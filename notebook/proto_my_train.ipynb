{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PL Trainer の訓練をoptunaに対応させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:36: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../script/')\n",
    "from os.path import exists\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "import utils\n",
    "import models\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(pl.Callback):\n",
    "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        self.metrics.append(trainer.callback_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add folds No. for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fold = \"../input/folds/train_folds.csv\"\n",
    "if not exists(path_fold):\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "    df.loc[:, \"kfold\"] = -1\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    targets = df.drop(\"sig_id\", axis=1).values\n",
    "\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "    for fold_, (tr_, va_) in enumerate(mskf.split(X=df, y=targets)):\n",
    "        df.loc[va_, \"kfold\"] = fold_\n",
    "    df.to_csv(path_fold, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params for training function `run_training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "# optuna 使わないので適当\n",
    "params = {\n",
    "    \"num_layers\": 3,\n",
    "    \"hidden_size\": 16,\n",
    "    \"dropout\": 0.3,\n",
    "    \"learning_rate\": 1e-3,\n",
    "}\n",
    "save_model=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prototyping training process from HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\n",
    "df = utils.process_data(df)\n",
    "folds = pd.read_csv(\"../input/folds/train_folds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create aux target \n",
    "`nsc_labels` means # of labels found in non-scored train set Which is not available in test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "      <th>nsc_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_09f3cdc66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_83659b848</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_17e3b5c2d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_29e34a9e1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_cabd98a36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_09f3cdc66                            0                       0   \n",
       "1  id_83659b848                            0                       0   \n",
       "2  id_17e3b5c2d                            0                       0   \n",
       "3  id_29e34a9e1                            0                       0   \n",
       "4  id_cabd98a36                            0                       0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0               0                               0   \n",
       "1               0                               0   \n",
       "2               0                               0   \n",
       "3               0                               0   \n",
       "4               0                               0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                           0  ...                0                  0   \n",
       "1                           0  ...                0                  0   \n",
       "2                           0  ...                0                  0   \n",
       "3                           0  ...                0                  0   \n",
       "4                           0  ...                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                0          0                           0              0   \n",
       "1                0          0                           0              0   \n",
       "2                0          0                           0              0   \n",
       "3                0          0                           0              0   \n",
       "4                0          0                           0              0   \n",
       "\n",
       "   kfold  nsc_labels  \n",
       "0      0           0  \n",
       "1      4           0  \n",
       "2      4           1  \n",
       "3      3           0  \n",
       "4      1           0  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_scored_df = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\n",
    "targets_non_scored = non_scored_df.drop(\"sig_id\", axis=1).to_numpy().sum(axis=1)\n",
    "non_scored_df.loc[:, \"nsc_labels\"] = targets_non_scored\n",
    "drop_cols = [c for c in non_scored_df.columns if c not in (\"nsc_labels\", \"sig_id\")]\n",
    "non_scored_df = non_scored_df.drop(drop_cols, axis=1)\n",
    "folds = folds.merge(non_scored_df, on=\"sig_id\", how=\"left\")\n",
    "folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = folds.drop([\"sig_id\", \"kfold\"], axis=1).columns\n",
    "features = df.drop(\"sig_id\", axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(folds, on=\"sig_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold No.  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'[Fold No.{fold:>3}]\\n')\n",
    "train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "valid_df = df[df.kfold == fold].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = train_df[features].to_numpy()\n",
    "x_va = valid_df[features].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = train_df[targets].to_numpy()\n",
    "y_va = valid_df[targets].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "metrics_callback = MetricsCallback()\n",
    "trainer = pl.Trainer(logger=False, gpus=1, max_epochs=5, weights_summary=\"full\", callbacks=[metrics_callback])\n",
    "# add param early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.LitMoA(\n",
    "    hparams={},\n",
    "    model=models.BaseLine2(\n",
    "        num_features=x_tr.shape[1],\n",
    "        num_targets=y_tr.shape[1],\n",
    "        num_layers=params[\"num_layers\"],\n",
    "        hidden_size=params[\"hidden_size\"],\n",
    "        dropout=params[\"dropout\"],\n",
    "    ),\n",
    ")\n",
    "dm = utils.MoADataModule(\n",
    "    hparams={\"train_size\": x_tr.shape[0]}, data=np.vstack([x_tr, x_va]), targets=np.vstack([y_tr, y_va])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_size': 19052}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name          | Type              | Params\n",
      "-----------------------------------------------------\n",
      "0  | model         | BaseLine2         | 18 K  \n",
      "1  | model.model   | Sequential        | 18 K  \n",
      "2  | model.model.0 | Linear            | 14 K  \n",
      "3  | model.model.1 | BatchNorm1d       | 32    \n",
      "4  | model.model.2 | Dropout           | 0     \n",
      "5  | model.model.3 | Linear            | 272   \n",
      "6  | model.model.4 | BatchNorm1d       | 32    \n",
      "7  | model.model.5 | Dropout           | 0     \n",
      "8  | model.model.6 | Linear            | 272   \n",
      "9  | model.model.7 | BatchNorm1d       | 32    \n",
      "10 | model.model.8 | Dropout           | 0     \n",
      "11 | model.model.9 | Linear            | 3 K   \n",
      "12 | criterion     | BCEWithLogitsLoss | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  79%|███████████████████████████████▋        | 19/24 [00:05<00:01,  3.46it/s, loss=0.722, training_loss=0.707]\n",
      "Validating: 0it [00:00, ?it/s]\n",
      "Epoch 0: 100%|██████████████████████| 24/24 [00:10<00:00,  2.28it/s, loss=0.722, training_loss=0.707, valid_loss=0.694]\n",
      "Epoch 1:  79%|███▏| 19/24 [00:05<00:01,  3.46it/s, loss=0.700, training_loss=0.691, valid_loss=0.694, train_loss=0.722]\n",
      "Validating: 0it [00:00, ?it/s]\n",
      "Epoch 1: 100%|████| 24/24 [00:10<00:00,  2.28it/s, loss=0.700, training_loss=0.691, valid_loss=0.675, train_loss=0.722]\n",
      "Epoch 2:  79%|███▏| 19/24 [00:05<00:01,  3.40it/s, loss=0.681, training_loss=0.671, valid_loss=0.675, train_loss=0.699]\n",
      "Validating: 0it [00:00, ?it/s]\n",
      "Epoch 2: 100%|█████| 24/24 [00:10<00:00,  2.25it/s, loss=0.681, training_loss=0.671, valid_loss=0.66, train_loss=0.699]\n",
      "Epoch 3:  79%|████▊ | 19/24 [00:05<00:01,  3.43it/s, loss=0.660, training_loss=0.646, valid_loss=0.66, train_loss=0.68]\n",
      "Validating: 0it [00:00, ?it/s]\n",
      "Epoch 3: 100%|█████| 24/24 [00:10<00:00,  2.26it/s, loss=0.660, training_loss=0.646, valid_loss=0.639, train_loss=0.68]\n",
      "Epoch 4:  79%|███▉ | 19/24 [00:05<00:01,  3.39it/s, loss=0.637, training_loss=0.627, valid_loss=0.639, train_loss=0.66]\n",
      "Validating: 0it [00:00, ?it/s]\n",
      "Epoch 4: 100%|█████| 24/24 [00:10<00:00,  2.25it/s, loss=0.637, training_loss=0.627, valid_loss=0.612, train_loss=0.66]\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████| 24/24 [00:10<00:00,  2.25it/s, loss=0.637, training_loss=0.627, valid_loss=0.612, train_loss=0.66]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6115400195121765"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_callback.metrics[-1][\"valid_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        os.path.join(MODEL_DIR, \"trial_{}\".format(trial.number), \"{epoch}\"), monitor=\"val_acc\"\n",
    "    )\n",
    "    metrics_callback = MetricsCallback()\n",
    "    \n",
    "    params = {\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 7),\n",
    "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 2048),\n",
    "        \"dropout\": trial.suggest_uniform(\"dropout\", 0.1, 0.8),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-3),\n",
    "    }\n",
    "    \n",
    "    metrics_callback = MetricsCallback()\n",
    "    trainer = pl.Trainer(\n",
    "        logger=False,\n",
    "        limit_val_batches=PERCENT_VALID_EXAMPLES,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        max_epochs=EPOCHS,\n",
    "        gpus=1 if torch.cuda.is_available() else None,\n",
    "        callbacks=[metrics_callback],\n",
    "        early_stop_callback=PyTorchLightningPruningCallback(trial, monitor=\"val_acc\"),\n",
    "    )\n",
    "\n",
    "    model = LightningNet(trial)\n",
    "    trainer.fit(model)\n",
    "\n",
    "    return metrics_callback.metrics[-1][\"val_acc\"].item()\n",
    "\n",
    "    loss_all = []\n",
    "    for fold_ in range(5):\n",
    "        loss_tmp = run_training(fold_, params, save_model=False)\n",
    "        loss_all.append(loss_tmp)\n",
    "    return np.mean(loss_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_te = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "df_te = utils.process_data(df_te)\n",
    "x_te = df_te[features].to_numpy()\n",
    "dataset_te = utils.TestMoaDataset(dataset=x_te)\n",
    "loader_te = torch.utils.data.DataLoader(\n",
    "    dataset_te, batch_size=1024, num_workers=4, shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((x_te.shape[0], 206))\n",
    "inference_model = model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model.eval()\n",
    "for ind, batch in enumerate(loader_te):\n",
    "    p = torch.sigmoid(inference_model(batch[\"x\"])).detach().cpu().numpy()\n",
    "    predictions[ind * 1024 : (ind + 1) * 1024] = p[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features1 = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "s = pd.DataFrame({\"sig_id\": test_features1[\"sig_id\"].values})\n",
    "\n",
    "for col in folds.columns[1:-2].tolist():\n",
    "    s[col] = 0\n",
    "s.loc[:, folds.columns[1:-2]] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[\n",
    "    s[\"sig_id\"].isin(test_features1.loc[test_features1[\"cp_type\"] == \"ctl_vehicle\", \"sig_id\"]),\n",
    "    folds.columns[1:-2],\n",
    "] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv(\"../submission/submission.csv\", index=False)\n",
    "torch.save(model.model.state_dict(), \"../weight/model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
