{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:36: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../script/')\n",
    "from os.path import exists\n",
    "import gc\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import train as trainer\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add folds No. for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fold = \"../input/folds/train_folds.csv\"\n",
    "if not exists(path_fold):\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n",
    "    df.loc[:, \"kfold\"] = -1\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    targets = df.drop(\"sig_id\", axis=1).values\n",
    "\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "    for fold_, (tr_, va_) in enumerate(mskf.split(X=df, y=targets)):\n",
    "        df.loc[va_, \"kfold\"] = fold_\n",
    "    df.to_csv(path_fold, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params for training function `run_training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "# optuna 使わないので適当\n",
    "params = {\n",
    "    \"num_layers\": 3,\n",
    "    \"hidden_size\": 16,\n",
    "    \"dropout\": 0.3,\n",
    "    \"learning_rate\": 1e-3,\n",
    "}\n",
    "save_model=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prototyping training process from HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/folds/train.csv\")\n",
    "with open(\"../input/folds/targets\", \"r\") as f:\n",
    "    targets = f.read().split(\"\\n\")\n",
    "with open(\"../input/folds/features\", \"r\") as f:\n",
    "    features = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold No.  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'[Fold No.{fold:>3}]\\n')\n",
    "train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "valid_df = df[df.kfold == fold].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = train_df[features].to_numpy()\n",
    "x_va = valid_df[features].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = train_df[targets].to_numpy()\n",
    "y_va = valid_df[targets].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=1024, num_workers=2)\n",
    "dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=1024, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseLine(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=879, out_features=16, bias=False)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (7): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Dropout(p=0.3, inplace=False)\n",
       "    (9): Linear(in_features=16, out_features=207, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BaseLine(\n",
    "    num_features=x_tr.shape[1],\n",
    "    num_targets=y_tr.shape[1],\n",
    "    params=params\n",
    ")\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=3, threshold=0.00001, mode=\"min\", verbose=True\n",
    ")\n",
    "eng = utils.Engine(model, optimizer, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, params, save_model=False):\n",
    "\n",
    "    df = pd.read_csv(\"../input/folds/train.csv\")\n",
    "    with open(\"../input/folds/targets\", \"r\") as f:\n",
    "        targets = f.read().split(\"\\n\")\n",
    "    with open(\"../input/folds/features\", \"r\") as f:\n",
    "        features = f.read().split(\"\\n\")\n",
    "\n",
    "    print(f\"\\n[Fold No.{fold:>2}]\\n\")\n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    x_tr = train_df[features].to_numpy()\n",
    "    x_va = valid_df[features].to_numpy()\n",
    "\n",
    "    y_tr = train_df[targets].to_numpy()\n",
    "    y_va = valid_df[targets].to_numpy()\n",
    "\n",
    "    # TODO: [BEGIN] NN以外の学習を記述\n",
    "    dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "    loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=1024, num_workers=2)\n",
    "    dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "    loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=1024, num_workers=2)\n",
    "    \n",
    "    model = models.BaseLine(\n",
    "        num_features=x_tr.shape[1],\n",
    "        num_targets=y_tr.shape[1],\n",
    "        params=params\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, patience=3, threshold=0.00001, mode=\"min\", verbose=True\n",
    "    )\n",
    "    eng = utils.Engine(model, optimizer, device=DEVICE)\n",
    "\n",
    "    # Free RAM space as much as possible before training\n",
    "    del df, train_df, valid_df, x_tr, x_va, y_tr, y_va\n",
    "    gc.collect()\n",
    "    \n",
    "    loss_best = np.inf\n",
    "    patience = 10\n",
    "    patience_cnt = 0\n",
    "    for ep in range(EPOCHS):\n",
    "        loss_tr = eng.train(loader_tr)\n",
    "        loss_va = eng.validate(loader_va)\n",
    "        scheduler.step(loss_va)\n",
    "        print(f\"epoch:{ep:>3}, train:{loss_tr:>.5}, valid:{loss_va:>.5}\")\n",
    "        \n",
    "        if loss_va < loss_best:\n",
    "            loss_best = loss_va\n",
    "            if save_model:\n",
    "                pass\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "        if patience_cnt > patience:\n",
    "            break\n",
    "    \n",
    "    print(f\"[Fold No.{fold:>2}]\")\n",
    "    print(f\"epoch:{ep:>3}, train:{loss_tr:>.5}, valid:{loss_va:>.5}\")\n",
    "\n",
    "    # TODO: [END] NN以外の学習を記述\n",
    "\n",
    "    # if save_model:\n",
    "    #     now = datetime.now()\n",
    "    #     now = str(now)[5:17].replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    #     filename = f\"weight/model{now}.pt\"\n",
    "    #     torch.save(model.model.state_dict(), filename)\n",
    "    #     print(\"model saved at:\", filename)\n",
    "\n",
    "    return loss_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 7),\n",
    "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 2048),\n",
    "        \"dropout\": trial.suggest_uniform(\"dropout\", 0.1, 0.8),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-3),\n",
    "    }\n",
    "    loss_all = []\n",
    "    for fold_ in range(5):\n",
    "        loss_tmp = run_training(fold_, params, save_model=False)\n",
    "        loss_all.append(loss_tmp)\n",
    "    return np.mean(loss_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.74813, valid:0.71099\n",
      "epoch:  1, train:0.7466, valid:0.71391\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.7466, valid:0.71391\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.74549, valid:0.70845\n",
      "epoch:  1, train:0.74416, valid:0.71114\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.74416, valid:0.71114\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.74679, valid:0.71024\n",
      "epoch:  1, train:0.74554, valid:0.71293\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.74554, valid:0.71293\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.74808, valid:0.71028\n",
      "epoch:  1, train:0.74632, valid:0.71396\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.74632, valid:0.71396\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.74822, valid:0.71147\n",
      "epoch:  1, train:0.74685, valid:0.71453\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.74685, valid:0.71453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:04:21,227] Trial 0 finished with value: 0.7102886772155762 and parameters: {'num_layers': 2, 'hidden_size': 1529, 'dropout': 0.34161654376166556, 'learning_rate': 1.2743274573140588e-06}. Best is trial 0 with value: 0.7102886772155762.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.71985, valid:0.70478\n",
      "epoch:  1, train:0.70747, valid:0.69886\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.70747, valid:0.69886\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.72046, valid:0.70449\n",
      "epoch:  1, train:0.70781, valid:0.69807\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.70781, valid:0.69807\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.7201, valid:0.70511\n",
      "epoch:  1, train:0.70745, valid:0.69858\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.70745, valid:0.69858\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.71958, valid:0.70408\n",
      "epoch:  1, train:0.70692, valid:0.698\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.70692, valid:0.698\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.72049, valid:0.70556\n",
      "epoch:  1, train:0.7079, valid:0.69966\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.7079, valid:0.69966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:05:31,640] Trial 1 finished with value: 0.6986337685585022 and parameters: {'num_layers': 1, 'hidden_size': 1521, 'dropout': 0.1489272533869646, 'learning_rate': 5.2721571424316446e-05}. Best is trial 1 with value: 0.6986337685585022.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.77117, valid:0.69256\n",
      "epoch:  1, train:0.74859, valid:0.68825\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.74859, valid:0.68825\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.77073, valid:0.69122\n",
      "epoch:  1, train:0.74772, valid:0.68778\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.74772, valid:0.68778\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.77033, valid:0.69174\n",
      "epoch:  1, train:0.74635, valid:0.68841\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.74635, valid:0.68841\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.77099, valid:0.6919\n",
      "epoch:  1, train:0.74797, valid:0.68884\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.74797, valid:0.68884\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.7703, valid:0.69265\n",
      "epoch:  1, train:0.74733, valid:0.68812\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.74733, valid:0.68812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:06:41,913] Trial 2 finished with value: 0.688279824256897 and parameters: {'num_layers': 4, 'hidden_size': 1253, 'dropout': 0.6263121146674873, 'learning_rate': 0.00012429219505052152}. Best is trial 2 with value: 0.688279824256897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.77938, valid:0.69243\n",
      "epoch:  1, train:0.77581, valid:0.69193\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.77581, valid:0.69193\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.77969, valid:0.69275\n",
      "epoch:  1, train:0.77576, valid:0.69206\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.77576, valid:0.69206\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.77993, valid:0.693\n",
      "epoch:  1, train:0.77577, valid:0.69249\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.77577, valid:0.69249\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.78108, valid:0.69406\n",
      "epoch:  1, train:0.77672, valid:0.69343\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.77672, valid:0.69343\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.77869, valid:0.69246\n",
      "epoch:  1, train:0.7751, valid:0.69179\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.7751, valid:0.69179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:07:53,780] Trial 3 finished with value: 0.6923413634300232 and parameters: {'num_layers': 6, 'hidden_size': 1487, 'dropout': 0.6137683996460142, 'learning_rate': 2.012239872677871e-05}. Best is trial 2 with value: 0.688279824256897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.75159, valid:0.69304\n",
      "epoch:  1, train:0.74212, valid:0.69195\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.74212, valid:0.69195\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.75312, valid:0.69412\n",
      "epoch:  1, train:0.74369, valid:0.69308\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.74369, valid:0.69308\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.75255, valid:0.69445\n",
      "epoch:  1, train:0.74299, valid:0.69376\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.74299, valid:0.69376\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.752, valid:0.69373\n",
      "epoch:  1, train:0.74277, valid:0.69257\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.74277, valid:0.69257\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.75099, valid:0.69321\n",
      "epoch:  1, train:0.74188, valid:0.69246\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.74188, valid:0.69246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:09:05,825] Trial 4 finished with value: 0.6927657365798949 and parameters: {'num_layers': 5, 'hidden_size': 1797, 'dropout': 0.43163043830325076, 'learning_rate': 2.7207315760446225e-05}. Best is trial 2 with value: 0.688279824256897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.73022, valid:0.7145\n",
      "epoch:  1, train:0.72118, valid:0.71118\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.72118, valid:0.71118\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.73014, valid:0.71221\n",
      "epoch:  1, train:0.72077, valid:0.70989\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.72077, valid:0.70989\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.73109, valid:0.7143\n",
      "epoch:  1, train:0.72192, valid:0.71135\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.72192, valid:0.71135\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.73183, valid:0.71535\n",
      "epoch:  1, train:0.72254, valid:0.71223\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.72254, valid:0.71223\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.72961, valid:0.71402\n",
      "epoch:  1, train:0.72082, valid:0.71084\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.72082, valid:0.71084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:10:16,050] Trial 5 finished with value: 0.7110964179039001 and parameters: {'num_layers': 1, 'hidden_size': 841, 'dropout': 0.17562153870582936, 'learning_rate': 1.9077043494166626e-05}. Best is trial 2 with value: 0.688279824256897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.72733, valid:0.69675\n",
      "epoch:  1, train:0.71426, valid:0.69511\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.71426, valid:0.69511\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.72666, valid:0.69546\n",
      "epoch:  1, train:0.71352, valid:0.69414\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.71352, valid:0.69414\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.72864, valid:0.69786\n",
      "epoch:  1, train:0.71543, valid:0.69682\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.71543, valid:0.69682\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.72767, valid:0.69625\n",
      "epoch:  1, train:0.71409, valid:0.69505\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.71409, valid:0.69505\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.7283, valid:0.69737\n",
      "epoch:  1, train:0.7155, valid:0.69605\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.7155, valid:0.69605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:11:27,980] Trial 6 finished with value: 0.6954344272613525 and parameters: {'num_layers': 4, 'hidden_size': 1040, 'dropout': 0.1637981163071046, 'learning_rate': 2.4158962418410857e-05}. Best is trial 2 with value: 0.688279824256897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.72825, valid:0.69475\n",
      "epoch:  1, train:0.71814, valid:0.69598\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.71814, valid:0.69598\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.72887, valid:0.69492\n",
      "epoch:  1, train:0.71851, valid:0.69614\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.71851, valid:0.69614\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.72779, valid:0.69425\n",
      "epoch:  1, train:0.71734, valid:0.69568\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.71734, valid:0.69568\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.72832, valid:0.6946\n",
      "epoch:  1, train:0.71815, valid:0.6962\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.71815, valid:0.6962\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.72801, valid:0.6943\n",
      "epoch:  1, train:0.71776, valid:0.69571\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.71776, valid:0.69571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:12:43,960] Trial 7 finished with value: 0.69456463098526 and parameters: {'num_layers': 7, 'hidden_size': 1742, 'dropout': 0.10869602554920929, 'learning_rate': 7.117593740794063e-06}. Best is trial 2 with value: 0.688279824256897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.81941, valid:0.69416\n",
      "epoch:  1, train:0.8123, valid:0.69372\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.8123, valid:0.69372\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.81889, valid:0.69376\n",
      "epoch:  1, train:0.81058, valid:0.69301\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.81058, valid:0.69301\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.81807, valid:0.69342\n",
      "epoch:  1, train:0.81115, valid:0.69301\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.81115, valid:0.69301\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.81823, valid:0.69396\n",
      "epoch:  1, train:0.81041, valid:0.69351\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.81041, valid:0.69351\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.81679, valid:0.69183\n",
      "epoch:  1, train:0.80941, valid:0.69143\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.80941, valid:0.69143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:13:56,154] Trial 8 finished with value: 0.6929359364509583 and parameters: {'num_layers': 4, 'hidden_size': 719, 'dropout': 0.7508156278904834, 'learning_rate': 2.9549937724242617e-05}. Best is trial 2 with value: 0.688279824256897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No. 0]\n",
      "\n",
      "epoch:  0, train:0.72218, valid:0.69422\n",
      "epoch:  1, train:0.70649, valid:0.69164\n",
      "[Fold No. 0]\n",
      "epoch:  1, train:0.70649, valid:0.69164\n",
      "\n",
      "[Fold No. 1]\n",
      "\n",
      "epoch:  0, train:0.72237, valid:0.69415\n",
      "epoch:  1, train:0.70677, valid:0.69154\n",
      "[Fold No. 1]\n",
      "epoch:  1, train:0.70677, valid:0.69154\n",
      "\n",
      "[Fold No. 2]\n",
      "\n",
      "epoch:  0, train:0.72256, valid:0.69515\n",
      "epoch:  1, train:0.70696, valid:0.69208\n",
      "[Fold No. 2]\n",
      "epoch:  1, train:0.70696, valid:0.69208\n",
      "\n",
      "[Fold No. 3]\n",
      "\n",
      "epoch:  0, train:0.72187, valid:0.69431\n",
      "epoch:  1, train:0.70582, valid:0.69136\n",
      "[Fold No. 3]\n",
      "epoch:  1, train:0.70582, valid:0.69136\n",
      "\n",
      "[Fold No. 4]\n",
      "\n",
      "epoch:  0, train:0.72246, valid:0.69475\n",
      "epoch:  1, train:0.70685, valid:0.69192\n",
      "[Fold No. 4]\n",
      "epoch:  1, train:0.70685, valid:0.69192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-04 15:15:09,259] Trial 9 finished with value: 0.6917083716392517 and parameters: {'num_layers': 4, 'hidden_size': 1721, 'dropout': 0.17363401146073038, 'learning_rate': 3.446642745757357e-05}. Best is trial 2 with value: 0.688279824256897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- ---- ---- ---- ----\n",
      "Best trial:\n",
      "Value: 0.688279824256897\n",
      "Params: \n",
      "{'num_layers': 4, 'hidden_size': 1253, 'dropout': 0.6263121146674873, 'learning_rate': 0.00012429219505052152}\n"
     ]
    }
   ],
   "source": [
    "is_pruning = True  # TODO: Impl as Param in future\n",
    "\n",
    "partial_obj = partial(objective)\n",
    "pruner = optuna.pruners.MedianPruner() if is_pruning else optuna.pruners.NopPruner()\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "study.optimize(partial_obj, n_trials=10) # i want to use \"timeout\" in practice\n",
    "\n",
    "print(\"\\n---- ---- ---- ---- ----\\nBest trial:\")\n",
    "trial_best = study.best_trial\n",
    "\n",
    "print(f\"Value: {trial_best.value}\")\n",
    "print(\"Params: \")\n",
    "best_params = trial_best.params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_te = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "df_te = utils.process_data(df_te)\n",
    "x_te = df_te[features].to_numpy()\n",
    "dataset_te = utils.TestMoaDataset(dataset=x_te)\n",
    "loader_te = torch.utils.data.DataLoader(\n",
    "    dataset_te, batch_size=1024, num_workers=4, shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = np.zeros((x_te.shape[0], 206))\n",
    "inference_model = model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference_model.eval()\n",
    "for ind, batch in enumerate(loader_te):\n",
    "    p = torch.sigmoid(inference_model(batch[\"x\"])).detach().cpu().numpy()\n",
    "    predictions[ind * 1024 : (ind + 1) * 1024] = p[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_features1 = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "s = pd.DataFrame({\"sig_id\": test_features1[\"sig_id\"].values})\n",
    "\n",
    "for col in folds.columns[1:-2].tolist():\n",
    "    s[col] = 0\n",
    "s.loc[:, folds.columns[1:-2]] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.loc[\n",
    "    s[\"sig_id\"].isin(test_features1.loc[test_features1[\"cp_type\"] == \"ctl_vehicle\", \"sig_id\"]),\n",
    "    folds.columns[1:-2],\n",
    "] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s.to_csv(\"../submission/submission.csv\", index=False)\n",
    "torch.save(model.model.state_dict(), \"../weight/model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
