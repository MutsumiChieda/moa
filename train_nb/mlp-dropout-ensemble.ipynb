{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../script/')\n",
    "import os\n",
    "from os.path import exists\n",
    "from datetime import datetime\n",
    "import json\n",
    "import gc\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from adabelief_pytorch import AdaBelief\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import train as trainer\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "# EPOCHS = 3000\n",
    "MODELNAME = \"Baseline1122\"\n",
    "# if not exists(MODELNAME):\n",
    "#     os.makedirs(f\"{MODELNAME}/tensorboard\")\n",
    "# now = datetime.now()\n",
    "# now = str(now)[5:17].replace(\" \", \"_\").replace(\":\", \"\")\n",
    "# writer = SummaryWriter(log_dir=f\"{MODELNAME}/tensorboard\")\n",
    "\n",
    "WEIGHT_PATHS = [f'{MODELNAME}/11-26_0045_fold{i}.pt' for i in range(5)]\n",
    "PARAMS_PATH = f'{MODELNAME}/11-26_0045_params.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: クラスタごとに並べてConv1d\n",
    "class BaseLine(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, num_layers=3, dropout=.2, hidden_size=256, activation=\"relu\", batchnorm=True, weight_norm=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.utils.weight_norm(nn.Linear(num_features if len(layers)==0 else hidden_size, hidden_size, bias=(not batchnorm))))\n",
    "            if batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            if activation == \"relu\":\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation == \"prelu\":\n",
    "                layers.append(nn.PReLU())\n",
    "            else:\n",
    "                raise RuntimeError(f'{activation} is not implemented')\n",
    "        # layers.append(nn.utils.weight_norm(nn.Linear(hidden_size, num_targets)))\n",
    "        layers.append(nn.Linear(hidden_size, num_targets))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/folds/train.csv\")\n",
    "with open(\"../input/folds/targets\", \"r\") as f:\n",
    "    targets = f.read().split(\"\\n\")[:-1]\n",
    "with open(\"../input/folds/features\", \"r\") as f:\n",
    "    features = f.read().split(\"\\n\")\n",
    "with open(PARAMS_PATH) as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_metric(y_true, y_pred):\n",
    "    y_pred_clip = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = - np.mean(np.mean(y_true * np.log(y_pred_clip) + (1 - y_true) * np.log(1 - y_pred_clip), axis = 1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predicting as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold No.  4] Predicting...\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros((df.shape[0], len(targets)))\n",
    "for fold in range(5):\n",
    "    print(f'[Fold No.{fold:>3}] Predicting...', end='\\r')\n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "    va_idx = df[df.kfold == fold].index\n",
    "    \n",
    "    x_tr = train_df[features].to_numpy()\n",
    "    x_va = valid_df[features].to_numpy()\n",
    "\n",
    "    y_tr = train_df[targets].to_numpy()\n",
    "    y_va = valid_df[targets].to_numpy()\n",
    "\n",
    "    dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "    loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=512, num_workers=2, pin_memory=True)\n",
    "    dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "    loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=512, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    model = BaseLine(num_features=x_tr.shape[1], num_targets=y_tr.shape[1], **params['nn_params'])\n",
    "    \n",
    "    weight = torch.load(WEIGHT_PATHS[fold], map_location=torch.device(DEVICE))\n",
    "    weight = OrderedDict([(f'model.{k}', v) for k, v in weight.items()])\n",
    "    model.load_state_dict(weight)\n",
    "    \n",
    "    model.eval()\n",
    "    ps = []\n",
    "    for ind, batch in enumerate(loader_va):\n",
    "        ps.append(torch.sigmoid(model(batch[\"x\"])).detach().cpu().numpy())\n",
    "    ps = np.vstack(ps)\n",
    "    predictions[va_idx] += ps\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score               : 0.016269\n",
      "CV score w/ postprocess: 0.0161582\n"
     ]
    }
   ],
   "source": [
    "print(f'CV score               : {log_loss_metric(df[targets].values, predictions):.6}')\n",
    "predictions_ = predictions.copy()\n",
    "predictions_ = np.clip(predictions_,0.0005,0.999)\n",
    "predictions_[df[\"cp_type_ctl_vehicle\"]==1] = 0\n",
    "print(f'CV score w/ postprocess: {log_loss_metric(df[targets].values, predictions_):.6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting w/ dropout ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRIAL No.   0] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   1] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   2] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   3] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   4] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   5] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   6] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   7] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   8] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   9] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  10] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  11] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  12] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  13] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  14] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  15] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  16] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  17] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  18] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  19] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  20] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  21] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  22] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  23] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  24] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  25] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  26] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  27] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  28] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  29] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  30] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  31] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  32] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  33] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  34] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  35] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  36] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  37] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  38] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  39] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  40] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  41] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  42] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  43] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  44] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  45] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  46] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  47] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  48] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  49] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  50] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  51] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  52] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  53] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  54] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  55] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  56] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  57] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  58] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  59] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  60] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  61] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  62] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  63] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  64] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  65] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  66] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  67] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  68] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  69] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  70] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  71] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  72] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  73] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  74] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  75] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  76] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  77] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  78] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  79] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  80] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  81] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  82] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  83] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  84] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  85] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  86] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  87] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  88] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  89] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  90] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  91] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  92] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  93] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  94] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  95] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  96] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  97] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  98] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  99] [Fold No.  4] Predicting...\n"
     ]
    }
   ],
   "source": [
    "sg = nn.Sigmoid()\n",
    "N_TRIALS = 100\n",
    "predictions = np.zeros((df.shape[0], len(targets)))\n",
    "for seed in range(N_TRIALS):\n",
    "    for fold in range(5):\n",
    "        print(f'[TRIAL No. {seed:>3}] [Fold No.{fold:>3}] Predicting...', end='\\r')\n",
    "        train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "        valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "        va_idx = df[df.kfold == fold].index\n",
    "\n",
    "        x_tr = train_df[features].to_numpy()\n",
    "        x_va = valid_df[features].to_numpy()\n",
    "\n",
    "        y_tr = train_df[targets].to_numpy()\n",
    "        y_va = valid_df[targets].to_numpy()\n",
    "\n",
    "        dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "        loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=512, num_workers=2, pin_memory=True)\n",
    "        dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "        loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=512, num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = BaseLine(num_features=x_tr.shape[1], num_targets=y_tr.shape[1], **params['nn_params'])\n",
    "\n",
    "        weight = torch.load(WEIGHT_PATHS[fold], map_location=torch.device(DEVICE))\n",
    "        weight = OrderedDict([(f'model.{k}', v) for k, v in weight.items()])\n",
    "        model.load_state_dict(weight)\n",
    "\n",
    "        model.train()\n",
    "        ps = []\n",
    "        for ind, batch in enumerate(loader_va):\n",
    "            ps.append(torch.sigmoid(model(batch[\"x\"])).detach().cpu().numpy())\n",
    "        ps = np.vstack(ps)\n",
    "        predictions[va_idx] += ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score               : 0.0163489\n",
      "CV score w/ postprocess: 0.0162451\n"
     ]
    }
   ],
   "source": [
    "print(f'CV score               : {log_loss_metric(df[targets].values, predictions):.6}')\n",
    "predictions_ = predictions.copy()\n",
    "predictions_ = np.clip(predictions_,0.0005,0.999)\n",
    "predictions_[df[\"cp_type_ctl_vehicle\"]==1] = 0\n",
    "print(f'CV score w/ postprocess: {log_loss_metric(df[targets].values, predictions_):.6}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
