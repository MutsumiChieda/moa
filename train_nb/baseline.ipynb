{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../script/')\n",
    "import os\n",
    "from os.path import exists\n",
    "import gc\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import optuna\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import train as trainer\n",
    "DEVICE = \"cuda\"\n",
    "EPOCHS = 3\n",
    "MODELNAME = \"Baseline1013\"\n",
    "if not exists(MODELNAME):\n",
    "    os.makedirs(f\"{MODELNAME}/tensorboard\")\n",
    "save_model = False\n",
    "writer = SummaryWriter(log_dir=f\"{MODELNAME}/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/folds/train.csv\")\n",
    "with open(\"../input/folds/targets\", \"r\") as f:\n",
    "    targets = f.read().split(\"\\n\")\n",
    "with open(\"../input/folds/features\", \"r\") as f:\n",
    "    features = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold No.  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "print(f'[Fold No.{fold:>3}]\\n')\n",
    "train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "valid_df = df[df.kfold == fold].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = train_df[features].to_numpy()\n",
    "x_va = valid_df[features].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = train_df[targets].to_numpy()\n",
    "y_va = valid_df[targets].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"nn_params\": {\"dropout\": 0.2, \"num_layers\": 3, \"hidden_size\": 256, \"activation\": \"relu\", \"batchnorm\": True},\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"optim_params\": {\"lr\": 1e-2, \"momentum\": 0.0},\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"scdl_params\": {\"threshold\": 0.00001},\n",
    "    \"batch_size\": 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=params['batch_size'], num_workers=2)\n",
    "dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=params['batch_size'], num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLine(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, num_layers=3, dropout=.2, hidden_size=256, activation=\"relu\", batchnorm=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(num_features if len(layers)==0 else hidden_size, hidden_size, bias=(not batchnorm)))\n",
    "            if batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            if activation == \"relu\":\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation == \"prelu\":\n",
    "                layers.append(nn.PReLU())\n",
    "            else:\n",
    "                raise RuntimeError(f'{activation} is not implemented')\n",
    "        layers.append(nn.Linear(hidden_size, num_targets))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseLine(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=879, out_features=256, bias=False)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): Dropout(p=0.2, inplace=False)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=256, out_features=207, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaseLine(num_features=x_tr.shape[1], num_targets=y_tr.shape[1], **params['nn_params'])\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"optimizer\"] == \"SGD\":\n",
    "    optimizer = torch.optim.SGD(model.parameters(), **params[\"optim_params\"])\n",
    "elif params[\"optimizer\"] == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), **params[\"optim_params\"])\n",
    "else:\n",
    "    raise RuntimeError(f'{params[\"optimizer\"]} is not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, mode=\"min\", **params[\"scdl_params\"])\n",
    "else: \n",
    "    print(\"Not Implemented: No scheduling will be applied\")\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda ep: 1**ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng = utils.Engine(model, optimizer, device=DEVICE)\n",
    "\n",
    "del df, train_df, valid_df, x_tr, x_va, y_tr, y_va\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_best = np.inf\n",
    "patience = 10\n",
    "patience_cnt = 0\n",
    "for ep in range(EPOCHS):\n",
    "    loss_tr = eng.train(loader_tr)\n",
    "    loss_va = eng.validate(loader_va)\n",
    "    scheduler.step(loss_va)\n",
    "    writer.add_scalar('loss/train', loss_tr, ep)\n",
    "    writer.add_scalar('loss/valid', loss_va, ep)\n",
    "    if loss_va < loss_best:\n",
    "        loss_best = loss_va\n",
    "        if save_model:\n",
    "            pass\n",
    "    else:\n",
    "        patience_cnt += 1\n",
    "    if patience_cnt > patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved at: Baseline1013/fold0.pt\n"
     ]
    }
   ],
   "source": [
    "filename = f\"{MODELNAME}/fold{fold}.pt\"\n",
    "torch.save(model.model.state_dict(), filename)\n",
    "print(\"model saved at:\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
