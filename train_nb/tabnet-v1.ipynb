{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041512,
     "end_time": "2020-11-14T07:03:43.125971",
     "exception": false,
     "start_time": "2020-11-14T07:03:43.084459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "www.kaggle.com/hiramcho/moa-tabnet-with-pca-rank-gauss  \n",
    "v1: preprocessing w/ the following:  \n",
    "- no ctl_vehicle\n",
    "- Rank Gauss Process\n",
    "- PCA\n",
    "- OneHot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039533,
     "end_time": "2020-11-14T07:03:43.205820",
     "exception": false,
     "start_time": "2020-11-14T07:03:43.166287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class = \"alert alert-block alert-info\">\n",
    "    <h1><font color = \"red\">DISCLAIMER</font></h1>\n",
    "    <p>The following notebook it's highly based on the works <a href = \"https://www.kaggle.com/optimo/tabnetregressor-2-0-train-infer\">TabNetRegressor 2.0 [TRAIN + INFER]</a>, <a href = \"https://www.kaggle.com/liuhdme/moa-competition/data\">MOA competition</a> and <a href = \"https://www.kaggle.com/kushal1506/moa-pytorch-0-01859-rankgauss-pca-nn/data?select=train_targets_scored.csv\">\n",
    "MoA | Pytorch | 0.01859 | RankGauss | PCA | NN</a>, please check it out. I have to add that i don't make this notebook for \"upvotes\" but feedback.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039383,
     "end_time": "2020-11-14T07:03:43.286344",
     "exception": false,
     "start_time": "2020-11-14T07:03:43.246961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color = \"seagreen\">Preambule</font>\n",
    "\n",
    "I made this notebook to share some experiments (see the sections \"Experiments\") which could help to someone who don't want to wast their daily \"submissions\", but more importantly, to get feedback about what i could change to achive a better CV. Moreover, the easiness of TabNet to overfit the data it's disturbing. In the section \"Conclusion\" i share my opinion about the fine-tuning process of TabNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03938,
     "end_time": "2020-11-14T07:03:43.365826",
     "exception": false,
     "start_time": "2020-11-14T07:03:43.326446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Installing Libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 59.273708,
     "end_time": "2020-11-14T07:04:42.679452",
     "exception": false,
     "start_time": "2020-11-14T07:03:43.405744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\kaggle\\input\\packages-for-lishmoa\\pytorch_tabnet-2.0.0-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Requirement '/kaggle/input/packages-for-lishmoa/pytorch_tabnet-2.0.0-py3-none-any.whl' looks like a filename, but the file does not exist\n",
      "ERROR: Could not install packages due to an EnvironmentError: [Errno 2] No such file or directory: 'C:\\\\kaggle\\\\input\\\\packages-for-lishmoa\\\\pytorch_tabnet-2.0.0-py3-none-any.whl'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iterative-stratification==0.1.6 from file:///C:/kaggle/input/packages-for-lishmoa/iterative_stratification-0.1.6-py3-none-any.whl in c:\\users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages (0.1.6)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Requirement '/kaggle/input/packages-for-lishmoa/iterative_stratification-0.1.6-py3-none-any.whl' looks like a filename, but the file does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages (from iterative-stratification==0.1.6) (0.23.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages (from iterative-stratification==0.1.6) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages (from iterative-stratification==0.1.6) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages (from scikit-learn->iterative-stratification==0.1.6) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\s3616\\anaconda3\\envs\\moa\\lib\\site-packages (from scikit-learn->iterative-stratification==0.1.6) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "# TabNet\n",
    "!pip install /kaggle/input/packages-for-lishmoa/pytorch_tabnet-2.0.0-py3-none-any.whl\n",
    "# Iterative Stratification\n",
    "!pip install /kaggle/input/packages-for-lishmoa/iterative_stratification-0.1.6-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044374,
     "end_time": "2020-11-14T07:04:42.768803",
     "exception": false,
     "start_time": "2020-11-14T07:04:42.724429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Loading Libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 2.599008,
     "end_time": "2020-11-14T07:04:45.412386",
     "exception": false,
     "start_time": "2020-11-14T07:04:42.813378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gauss_rank_scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6dba7e257c93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgauss_rank_scaler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussRankScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m### Data Visualization ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gauss_rank_scaler'"
     ]
    }
   ],
   "source": [
    "### General ###\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import gc\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"../input/packages-for-lishmoa/\")\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n",
    "\n",
    "### Data Wrangling ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "### Data Visualization ###\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "### Machine Learning ###\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "### Deep Learning ###\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# Tabnet \n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "### Make prettier the prints ###\n",
    "from colorama import Fore\n",
    "c_ = Fore.CYAN\n",
    "m_ = Fore.MAGENTA\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "g_ = Fore.GREEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044281,
     "end_time": "2020-11-14T07:04:45.501744",
     "exception": false,
     "start_time": "2020-11-14T07:04:45.457463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Reproducibility</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.061051,
     "end_time": "2020-11-14T07:04:45.608374",
     "exception": false,
     "start_time": "2020-11-14T07:04:45.547323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044222,
     "end_time": "2020-11-14T07:04:45.697667",
     "exception": false,
     "start_time": "2020-11-14T07:04:45.653445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Configuration</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.054057,
     "end_time": "2020-11-14T07:04:45.796873",
     "exception": false,
     "start_time": "2020-11-14T07:04:45.742816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_path = \"../input/lish-moa/\"\n",
    "no_ctl = False\n",
    "no_nonscored = True\n",
    "scale = \"rankgauss\"\n",
    "variance_threshould = 0.7\n",
    "decompo = \"PCA\"\n",
    "ncompo_genes = 80\n",
    "ncompo_cells = 10\n",
    "encoding = \"dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045996,
     "end_time": "2020-11-14T07:04:45.892057",
     "exception": false,
     "start_time": "2020-11-14T07:04:45.846061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Loading the Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 6.612039,
     "end_time": "2020-11-14T07:04:52.549547",
     "exception": false,
     "start_time": "2020-11-14T07:04:45.937508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path + \"train_features.csv\")\n",
    "#train.drop(columns = [\"sig_id\"], inplace = True)\n",
    "\n",
    "targets = pd.read_csv(data_path + \"train_targets_scored.csv\")\n",
    "#train_targets_scored.drop(columns = [\"sig_id\"], inplace = True)\n",
    "\n",
    "if not no_nonscored:\n",
    "    train_targets_nonscored = pd.read_csv(data_path + \"train_targets_nonscored.csv\")\n",
    "    train = train.merge(train_targets_nonscored, on='sig_id')\n",
    "\n",
    "test = pd.read_csv(data_path + \"test_features.csv\")\n",
    "#test.drop(columns = [\"sig_id\"], inplace = True)\n",
    "\n",
    "submission = pd.read_csv(data_path + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044561,
     "end_time": "2020-11-14T07:04:52.639348",
     "exception": false,
     "start_time": "2020-11-14T07:04:52.594787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color = \"seagreen\">Preprocessing and Feature Engineering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.198009,
     "end_time": "2020-11-14T07:04:52.882209",
     "exception": false,
     "start_time": "2020-11-14T07:04:52.684200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if no_ctl:\n",
    "    # cp_type == ctl_vehicle\n",
    "    print(b_, \"not_ctl\")\n",
    "    train = train[train[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "    test = test[test[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "    targets = targets.iloc[train.index]\n",
    "    train.reset_index(drop = True, inplace = True)\n",
    "    test.reset_index(drop = True, inplace = True)\n",
    "    targets.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045931,
     "end_time": "2020-11-14T07:04:52.974529",
     "exception": false,
     "start_time": "2020-11-14T07:04:52.928598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Distributions Before Rank Gauss and PCA</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.059848,
     "end_time": "2020-11-14T07:04:53.080693",
     "exception": false,
     "start_time": "2020-11-14T07:04:53.020845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distributions(num, graphs, items, features, gorc):\n",
    "    \"\"\"\n",
    "    Plot the distributions of gene expression or cell viability data\n",
    "    \"\"\"\n",
    "    for i in range(0, num - 1, 7):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        idxs = list(np.array([0, 1, 2, 3, 4, 5, 6]) + i)\n",
    "    \n",
    "        fig, axs = plt.subplots(1, 7, sharey = True)\n",
    "        for k, item in enumerate(idxs):\n",
    "            if item >= items:\n",
    "                break\n",
    "            graph = sns.distplot(train[features].values[:, item], ax = axs[k])\n",
    "            graph.set_title(f\"{gorc}-{item}\")\n",
    "            graphs.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.056438,
     "end_time": "2020-11-14T07:04:53.183111",
     "exception": false,
     "start_time": "2020-11-14T07:04:53.126673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in train.columns if col.startswith(\"c-\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046512,
     "end_time": "2020-11-14T07:04:53.275864",
     "exception": false,
     "start_time": "2020-11-14T07:04:53.229352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <font color = \"green\">Distributions of the Train Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.12523,
     "end_time": "2020-11-14T07:04:55.461592",
     "exception": false,
     "start_time": "2020-11-14T07:04:53.336362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gnum = train[GENES].shape[1]\n",
    "# graphs = []\n",
    "\n",
    "# distributions(gnum, graphs, 771, GENES, \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.832379,
     "end_time": "2020-11-14T07:04:57.342142",
     "exception": false,
     "start_time": "2020-11-14T07:04:55.509763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cnum = train[CELLS].shape[1]\n",
    "# graphs = []\n",
    "\n",
    "# distributions(cnum, graphs, 100, CELLS, \"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04824,
     "end_time": "2020-11-14T07:04:57.439233",
     "exception": false,
     "start_time": "2020-11-14T07:04:57.390993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <font color = \"green\">Distributions of the Test Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.042235,
     "end_time": "2020-11-14T07:04:59.530290",
     "exception": false,
     "start_time": "2020-11-14T07:04:57.488055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gnum = test[GENES].shape[1]\n",
    "# graphs = []\n",
    "\n",
    "# distributions(gnum, graphs, 771, GENES, \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.882201,
     "end_time": "2020-11-14T07:05:01.463053",
     "exception": false,
     "start_time": "2020-11-14T07:04:59.580852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cnum = test[CELLS].shape[1]\n",
    "# graphs = []\n",
    "\n",
    "# distributions(cnum, graphs, 100, CELLS, \"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062779,
     "end_time": "2020-11-14T07:05:01.585843",
     "exception": false,
     "start_time": "2020-11-14T07:05:01.523064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Rank Gauss Process</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.59313,
     "end_time": "2020-11-14T07:05:02.230766",
     "exception": false,
     "start_time": "2020-11-14T07:05:01.637636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_all = pd.concat([train, test], ignore_index = True)\n",
    "cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\n",
    "mask = (data_all[cols_numeric].var() >= variance_threshould).values\n",
    "tmp = data_all[cols_numeric].loc[:, mask]\n",
    "data_all = pd.concat([data_all[[\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]], tmp], axis = 1)\n",
    "cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 18.353351,
     "end_time": "2020-11-14T07:05:20.640367",
     "exception": false,
     "start_time": "2020-11-14T07:05:02.287016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_minmax(col):\n",
    "    return (col - col.min()) / (col.max() - col.min())\n",
    "\n",
    "def scale_norm(col):\n",
    "    return (col - col.mean()) / col.std()\n",
    "\n",
    "if scale == \"boxcox\":\n",
    "    print(b_, \"boxcox\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis = 0)\n",
    "    trans = []\n",
    "    for feat in cols_numeric:\n",
    "        trans_var, lambda_var = stats.boxcox(data_all[feat].dropna() + 1)\n",
    "        trans.append(scale_minmax(trans_var))\n",
    "    data_all[cols_numeric] = np.asarray(trans).T\n",
    "    \n",
    "elif scale == \"norm\":\n",
    "    print(b_, \"norm\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_norm, axis = 0)\n",
    "    \n",
    "elif scale == \"minmax\":\n",
    "    print(b_, \"minmax\")\n",
    "    data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis = 0)\n",
    "    \n",
    "elif scale == \"rankgauss\":\n",
    "    ### Rank Gauss ###\n",
    "    print(b_, \"Rank Gauss\")\n",
    "    scaler = GaussRankScaler()\n",
    "    data_all[cols_numeric] = scaler.fit_transform(data_all[cols_numeric])\n",
    "    \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052487,
     "end_time": "2020-11-14T07:05:20.745449",
     "exception": false,
     "start_time": "2020-11-14T07:05:20.692962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Principal Component Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.548078,
     "end_time": "2020-11-14T07:05:22.346354",
     "exception": false,
     "start_time": "2020-11-14T07:05:20.798276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "if decompo == \"PCA\":\n",
    "    print(b_, \"PCA\")\n",
    "    GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n",
    "    CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n",
    "    \n",
    "    pca_genes = PCA(n_components = ncompo_genes,\n",
    "                    random_state = seed).fit_transform(data_all[GENES])\n",
    "    pca_cells = PCA(n_components = ncompo_cells,\n",
    "                    random_state = seed).fit_transform(data_all[CELLS])\n",
    "    \n",
    "    pca_genes = pd.DataFrame(pca_genes, columns = [f\"pca_g-{i}\" for i in range(ncompo_genes)])\n",
    "    pca_cells = pd.DataFrame(pca_cells, columns = [f\"pca_c-{i}\" for i in range(ncompo_cells)])\n",
    "    data_all = pd.concat([data_all, pca_genes, pca_cells], axis = 1)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053007,
     "end_time": "2020-11-14T07:05:22.454798",
     "exception": false,
     "start_time": "2020-11-14T07:05:22.401791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">One Hot</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.335627,
     "end_time": "2020-11-14T07:05:22.843207",
     "exception": false,
     "start_time": "2020-11-14T07:05:22.507580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoding\n",
    "if encoding == \"lb\":\n",
    "    print(b_, \"Label Encoding\")\n",
    "    for feat in [\"cp_time\", \"cp_dose\"]:\n",
    "        data_all[feat] = LabelEncoder().fit_transform(data_all[feat])\n",
    "elif encoding == \"dummy\":\n",
    "    print(b_, \"One-Hot\")\n",
    "    data_all = pd.get_dummies(data_all, columns = [\"cp_time\", \"cp_dose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.986602,
     "end_time": "2020-11-14T07:05:27.883368",
     "exception": false,
     "start_time": "2020-11-14T07:05:22.896766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n",
    "\n",
    "for stats in tqdm.tqdm([\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]):\n",
    "    data_all[\"g_\" + stats] = getattr(data_all[GENES], stats)(axis = 1)\n",
    "    data_all[\"c_\" + stats] = getattr(data_all[CELLS], stats)(axis = 1)    \n",
    "    data_all[\"gc_\" + stats] = getattr(data_all[GENES + CELLS], stats)(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057567,
     "end_time": "2020-11-14T07:05:27.998887",
     "exception": false,
     "start_time": "2020-11-14T07:05:27.941320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Distributions After Rank Gauss and PCA</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.071989,
     "end_time": "2020-11-14T07:05:28.127759",
     "exception": false,
     "start_time": "2020-11-14T07:05:28.055770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distributions(num, graphs, items, features, gorc):\n",
    "    \"\"\"\n",
    "    Plot the distributions of gene expression or cell viability data\n",
    "    \"\"\"\n",
    "    for i in range(0, num - 1, 7):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        idxs = list(np.array([0, 1, 2, 3, 4, 5, 6]) + i)\n",
    "    \n",
    "        fig, axs = plt.subplots(1, 7, sharey = True)\n",
    "        for k, item in enumerate(idxs):\n",
    "            if item >= items:\n",
    "                break\n",
    "            graph = sns.distplot(data_all[features].values[:, item], ax = axs[k])\n",
    "            graph.set_title(f\"{gorc}-{item}\")\n",
    "            graphs.append(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060159,
     "end_time": "2020-11-14T07:05:28.248576",
     "exception": false,
     "start_time": "2020-11-14T07:05:28.188417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <font color = \"green\">Distributions of \"data_all\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.420758,
     "end_time": "2020-11-14T07:05:30.729638",
     "exception": false,
     "start_time": "2020-11-14T07:05:28.308880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gnum = data_all[GENES].shape[1]\n",
    "# graphs = []\n",
    "\n",
    "# distributions(gnum, graphs, 771, GENES, \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.823558,
     "end_time": "2020-11-14T07:05:32.615102",
     "exception": false,
     "start_time": "2020-11-14T07:05:30.791544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cnum = data_all[CELLS].shape[1]\n",
    "# graphs = []\n",
    "\n",
    "# distributions(cnum, graphs, 100, CELLS, \"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060576,
     "end_time": "2020-11-14T07:05:32.737122",
     "exception": false,
     "start_time": "2020-11-14T07:05:32.676546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can confirme that the shapes of data got close to the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.405688,
     "end_time": "2020-11-14T07:05:33.204103",
     "exception": false,
     "start_time": "2020-11-14T07:05:32.798415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data_all.pickle\", \"wb\") as f:\n",
    "    pickle.dump(data_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.410878,
     "end_time": "2020-11-14T07:05:33.675144",
     "exception": false,
     "start_time": "2020-11-14T07:05:33.264266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data_all.pickle\", \"rb\") as f:\n",
    "    data_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.156117,
     "end_time": "2020-11-14T07:05:33.891884",
     "exception": false,
     "start_time": "2020-11-14T07:05:33.735767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df and test_df\n",
    "features_to_drop = [\"sig_id\", \"cp_type\"]\n",
    "data_all.drop(features_to_drop, axis = 1, inplace = True)\n",
    "try:\n",
    "    targets.drop(\"sig_id\", axis = 1, inplace = True)\n",
    "except:\n",
    "    pass\n",
    "train_df = data_all[: train.shape[0]]\n",
    "train_df.reset_index(drop = True, inplace = True)\n",
    "# The following line it's a bad practice in my opinion, targets on train set\n",
    "#train_df = pd.concat([train_df, targets], axis = 1)\n",
    "test_df = data_all[train_df.shape[0]: ]\n",
    "test_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.072975,
     "end_time": "2020-11-14T07:05:34.026876",
     "exception": false,
     "start_time": "2020-11-14T07:05:33.953901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{b_}train_df.shape: {r_}{train_df.shape}\")\n",
    "print(f\"{b_}test_df.shape: {r_}{test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.08178,
     "end_time": "2020-11-14T07:05:34.170425",
     "exception": false,
     "start_time": "2020-11-14T07:05:34.088645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = test_df.values\n",
    "print(f\"{b_}X_test.shape: {r_}{X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.061687,
     "end_time": "2020-11-14T07:05:34.295533",
     "exception": false,
     "start_time": "2020-11-14T07:05:34.233846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color = \"seagreen\">Experiments</font>\n",
    "\n",
    "I just want to point that the [original work](https://www.kaggle.com/optimo/tabnetregressor-2-0-train-infer) achive a CV of 0.015532370835690834 and a LB score of 0.01864. Some of the experiments that i made with their changes:\n",
    "\n",
    "\n",
    "- CV: 0.01543560538566987, LB: 0.01858, best LB that i could achive, changes\n",
    "    - `n_a` = 32 instead of 24\n",
    "    - `n_d` = 32 instead of 24\n",
    "- CV: 0.015282077428722094, LB: 0.01862, best CV that i could achive, changes (Version 5):\n",
    "    - `n_a` = 32 instead of 24\n",
    "    - `n_d` = 32 instead of 24\n",
    "    - `virtual_batch_size` = 32, instead of 128\n",
    "    - `seed` = 42 instead of 0\n",
    "- CV: 0.015330138325308062, LB: 01864, the same LB that the original but better CV, changes:\n",
    "    - `n_a` = 32 instead of 24\n",
    "    - `n_d` = 32 instead of 24\n",
    "    - `virtual_batch_size` = 64, instead of 128\n",
    "    - `batch_size` = 512, instead of 1024\n",
    "- CV: 0.015361751699863063, LB: 0.01863, better LB and CV than the original, changes:\n",
    "    - `n_a` = 32 instead of 24\n",
    "    - `n_d` = 32 instead of 24\n",
    "    - `virtual_batch_size` = 64, instead of 128\n",
    "- CV: 0.015529925324634975, LB: 0.01865, changes:\n",
    "    - `n_a` = 48 instead of 24\n",
    "    - `n_d` = 48 instead of 24\n",
    "- CV: 0.015528553520924939, LB: 0.01868, changes:\n",
    "    - `n_a` = 12 instead of 24\n",
    "    - `n_d` = 12 instead of 24\n",
    "- CV: 0.015870202970324317, LB: 0.01876, worst CV and LB score, changes:\n",
    "    - `n_a` = 12 instead of 24\n",
    "    - `n_d` = 12 instead of 24\n",
    "    - `batch_size` = 2048, instead of 1024\n",
    "    \n",
    "    \n",
    "As you can see if `batch_size` < 1024 and > 1024 give worst results. Something similar happens with `n_a` and `n_d`, if their values are lower or higher than 32 the results are worst.\n",
    "\n",
    "\n",
    "## <font color = \"green\">Versions</font>\n",
    "\n",
    "- **Version 5**: I added the `seed` parameter to the TabNet model.\n",
    "- **Version 6**: I changed the `virtual_batch_size` to 24\n",
    "    - CV: 0.01532900616425282, LB: 0.01862, changes:\n",
    "        - `n_a` = 32 instead of 24\n",
    "        - `n_d` = 32 instead of 24\n",
    "        - `virtual_batch_size` = 24, instead of 128\n",
    "        - `seed` = 42 instead of 0\n",
    "- **Version 7**: PCA, Rank Gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.061816,
     "end_time": "2020-11-14T07:05:34.419408",
     "exception": false,
     "start_time": "2020-11-14T07:05:34.357592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color = \"seagreen\">Modeling</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.061561,
     "end_time": "2020-11-14T07:05:34.543041",
     "exception": false,
     "start_time": "2020-11-14T07:05:34.481480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Model Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.083075,
     "end_time": "2020-11-14T07:05:34.693378",
     "exception": false,
     "start_time": "2020-11-14T07:05:34.610303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH = 200\n",
    "# n_d and n_a are different from the original work, 32 instead of 24\n",
    "# This is the first change in the code from the original\n",
    "tabnet_params = dict(\n",
    "    n_d = 32,\n",
    "    n_a = 32,\n",
    "    n_steps = 1,\n",
    "    gamma = 1.3,\n",
    "    lambda_sparse = 0,\n",
    "    optimizer_fn = optim.Adam,\n",
    "    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(\n",
    "        mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n",
    "    scheduler_fn = ReduceLROnPlateau,\n",
    "    seed = seed,\n",
    "    verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.066263,
     "end_time": "2020-11-14T07:05:34.833954",
     "exception": false,
     "start_time": "2020-11-14T07:05:34.767691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <font color = \"green\">Custom Metric</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.07918,
     "end_time": "2020-11-14T07:05:34.990609",
     "exception": false,
     "start_time": "2020-11-14T07:05:34.911429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    \"\"\"\n",
    "    LogLoss with sigmoid applied\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute LogLoss of predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: np.ndarray\n",
    "            Target matrix or vector\n",
    "        y_score: np.ndarray\n",
    "            Score matrix or vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "            LogLoss of predictions vs targets.\n",
    "        \"\"\"\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062164,
     "end_time": "2020-11-14T07:05:35.115788",
     "exception": false,
     "start_time": "2020-11-14T07:05:35.053624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color = \"seagreen\">Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.073613,
     "end_time": "2020-11-14T07:05:35.259388",
     "exception": false,
     "start_time": "2020-11-14T07:05:35.185775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_auc_all = []\n",
    "test_cv_preds = []\n",
    "\n",
    "NB_SPLITS = 5 # 7\n",
    "mskf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, random_state = 0, shuffle = True)\n",
    "\n",
    "oof_preds = []\n",
    "oof_targets = []\n",
    "scores = []\n",
    "scores_auc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068256,
     "end_time": "2020-11-14T07:05:35.390865",
     "exception": false,
     "start_time": "2020-11-14T07:05:35.322609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color = \"seagreen\">Setting New CV</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.808496,
     "end_time": "2020-11-14T07:05:41.263154",
     "exception": false,
     "start_time": "2020-11-14T07:05:35.454658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "feats = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\n",
    "feats = feats[feats[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "scored = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\")\n",
    "scored = scored.iloc[feats.index]\n",
    "feats.reset_index(drop=True, inplace=True)\n",
    "scored.reset_index(drop=True, inplace=True)\n",
    "drug = pd.read_csv(\"/kaggle/input/lish-moa/train_drug.csv\")\n",
    "tgts = scored.columns[1:]\n",
    "scored = scored.merge(drug, on=\"sig_id\", how=\"left\")\n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = scored.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc <= 18].index.sort_values()\n",
    "vc2 = vc.loc[vc > 18].index.sort_values()\n",
    "\n",
    "# STRATIFY DRUGS 18X OR LESS\n",
    "dct1 = {}\n",
    "dct2 = {}\n",
    "skf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, shuffle=True, random_state=SEED)\n",
    "tmp = scored.groupby(\"drug_id\")[tgts].mean().loc[vc1]\n",
    "for fold, (idxT, idxV) in enumerate(skf.split(tmp, tmp[tgts])):\n",
    "    dd = {k: fold for k in tmp.index[idxV].values}\n",
    "    dct1.update(dd)\n",
    "\n",
    "# STRATIFY DRUGS MORE THAN 18X\n",
    "skf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, shuffle=True, random_state=SEED)\n",
    "tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "for fold, (idxT, idxV) in enumerate(skf.split(tmp, tmp[tgts])):\n",
    "    dd = {k: fold for k in tmp.sig_id[idxV].values}\n",
    "    dct2.update(dd)\n",
    "\n",
    "# ASSIGN FOLDS\n",
    "scored[\"kfold\"] = scored.drug_id.map(dct1)\n",
    "scored.loc[scored.kfold.isna(), \"kfold\"] = scored.loc[scored.kfold.isna(), \"sig_id\"].map(\n",
    "    dct2\n",
    ")\n",
    "kfold_idx = scored.kfold.astype(\"int8\")\n",
    "train_indices, val_indices = [], []\n",
    "for fold_nb in range(NB_SPLITS):\n",
    "    train_indices.append(kfold_idx[kfold_idx!=fold_nb].index.values)\n",
    "    val_indices.append(kfold_idx[kfold_idx==fold_nb].index.values)\n",
    "del feats, scored, drug, tgts, vc, vc1, vc2, dct1, dct2, skf, tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5189.432684,
     "end_time": "2020-11-14T08:32:10.759377",
     "exception": false,
     "start_time": "2020-11-14T07:05:41.326693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold_nb, (train_idx, val_idx) in enumerate(zip(train_indices, val_indices)):\n",
    "# for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train_df, targets)):\n",
    "    print(b_,\"FOLDS: \", r_, fold_nb + 1)\n",
    "    print(g_, '*' * 60, c_)\n",
    "    \n",
    "    X_train, y_train = train_df.values[train_idx, :], targets.values[train_idx, :]\n",
    "    X_val, y_val = train_df.values[val_idx, :], targets.values[val_idx, :]\n",
    "    ### Model ###\n",
    "    model = TabNetRegressor(**tabnet_params)\n",
    "        \n",
    "    ### Fit ###\n",
    "    # Another change to the original code\n",
    "    # virtual_batch_size of 32 instead of 128\n",
    "    model.fit(\n",
    "        X_train = X_train,\n",
    "        y_train = y_train,\n",
    "        eval_set = [(X_val, y_val)],\n",
    "        eval_name = [\"val\"],\n",
    "        eval_metric = [\"logits_ll\"],\n",
    "        max_epochs = MAX_EPOCH,\n",
    "        patience = 20,\n",
    "        batch_size = 1024, \n",
    "        virtual_batch_size = 32,\n",
    "        num_workers = 1,\n",
    "        drop_last = False,\n",
    "        # To use binary cross entropy because this is not a regression problem\n",
    "        loss_fn = F.binary_cross_entropy_with_logits\n",
    "    )\n",
    "    print(y_, '-' * 60)\n",
    "    \n",
    "    ### Predict on validation ###\n",
    "    preds_val = model.predict(X_val)\n",
    "    # Apply sigmoid to the predictions\n",
    "    preds = 1 / (1 + np.exp(-preds_val))\n",
    "    score = np.min(model.history[\"val_logits_ll\"])\n",
    "    \n",
    "    ### Save OOF for CV ###\n",
    "    oof_preds.append(preds_val)\n",
    "    oof_targets.append(y_val)\n",
    "    scores.append(score)\n",
    "    \n",
    "    ### Predict on test ###\n",
    "    preds_test = model.predict(X_test)\n",
    "    test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "\n",
    "oof_preds_all = np.concatenate(oof_preds)\n",
    "oof_targets_all = np.concatenate(oof_targets)\n",
    "test_preds_all = np.stack(test_cv_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.103139,
     "end_time": "2020-11-14T08:32:10.956377",
     "exception": false,
     "start_time": "2020-11-14T08:32:10.853238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.839866,
     "end_time": "2020-11-14T08:32:12.885975",
     "exception": false,
     "start_time": "2020-11-14T08:32:11.046109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aucs = []\n",
    "for task_id in range(oof_preds_all.shape[1]):\n",
    "    aucs.append(roc_auc_score(y_true = oof_targets_all[:, task_id],\n",
    "                              y_score = oof_preds_all[:, task_id]\n",
    "                             ))\n",
    "print(f\"{b_}Overall AUC: {r_}{np.mean(aucs)}\")\n",
    "print(f\"{b_}Average CV: {r_}{np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.089204,
     "end_time": "2020-11-14T08:32:13.064869",
     "exception": false,
     "start_time": "2020-11-14T08:32:12.975665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color = \"seagreen\">Conclusion (NOT AVAILABLE UNTIL I SEE THE LB Score)</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.089863,
     "end_time": "2020-11-14T08:32:13.245079",
     "exception": false,
     "start_time": "2020-11-14T08:32:13.155216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color = \"seagreen\">Submission</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.985091,
     "end_time": "2020-11-14T08:32:16.319303",
     "exception": false,
     "start_time": "2020-11-14T08:32:13.334212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_feat = [col for col in submission.columns if col not in [\"sig_id\"]]\n",
    "# To obtain the same lenght of test_preds_all and submission\n",
    "test = pd.read_csv(data_path + \"test_features.csv\")\n",
    "sig_id = test[test[\"cp_type\"] != \"ctl_vehicle\"].sig_id.reset_index(drop = True)\n",
    "tmp = pd.DataFrame(test_preds_all.mean(axis = 0), columns = all_feat)\n",
    "tmp[\"sig_id\"] = sig_id\n",
    "\n",
    "submission = pd.merge(test[[\"sig_id\"]], tmp, on = \"sig_id\", how = \"left\")\n",
    "submission.fillna(0, inplace = True)\n",
    "\n",
    "#submission[all_feat] = tmp.mean(axis = 0)\n",
    "\n",
    "# Set control to 0\n",
    "#submission.loc[test[\"cp_type\"] == 0, submission.columns[1:]] = 0\n",
    "submission.to_csv(\"submission.csv\", index = None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.099481,
     "end_time": "2020-11-14T08:32:16.509561",
     "exception": false,
     "start_time": "2020-11-14T08:32:16.410080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{b_}submission.shape: {r_}{submission.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "duration": 5319.871994,
   "end_time": "2020-11-14T08:32:17.684053",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-14T07:03:37.812059",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
