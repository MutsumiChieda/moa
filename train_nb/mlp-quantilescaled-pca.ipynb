{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../script/')\n",
    "import os\n",
    "from os.path import exists\n",
    "from datetime import datetime\n",
    "import json\n",
    "import gc\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from adabelief_pytorch import AdaBelief\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import train as trainer\n",
    "DEVICE = \"cuda\"\n",
    "# DEVICE = \"cpu\"\n",
    "EPOCHS = 3000\n",
    "MODELNAME = \"Baseline1125\"\n",
    "if not exists(MODELNAME):\n",
    "    os.makedirs(f\"{MODELNAME}/tensorboard\")\n",
    "now = datetime.now()\n",
    "now = str(now)[5:17].replace(\" \", \"_\").replace(\":\", \"\")\n",
    "writer = SummaryWriter(log_dir=f\"{MODELNAME}/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/folds/train.csv\")\n",
    "with open(\"../input/folds/targets\", \"r\") as f:\n",
    "    targets = f.read().split(\"\\n\")\n",
    "with open(\"../input/folds/features\", \"r\") as f:\n",
    "    features = f.read().split(\"\\n\")\n",
    "targets = targets[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile scaler + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantilePCA(df_tr, df_va, drop=True, seed=42):\n",
    "    gcols = [f'g-{i}' for i in range(772)]\n",
    "    ccols = [f'c-{i}' for i in range(100)]\n",
    "    \n",
    "    gdf_tr, gdf_va = df_tr[gcols].copy(), df_va[gcols].copy()\n",
    "    cdf_tr, cdf_va = df_tr[ccols].copy(), df_va[ccols].copy()    \n",
    "    print('QT  ',end='')\n",
    "    gqt = QuantileTransformer(random_state=seed)\n",
    "    cqt = QuantileTransformer(random_state=seed)\n",
    "    gdf_tr = gqt.fit_transform(gdf_tr)\n",
    "    cdf_tr = cqt.fit_transform(cdf_tr)\n",
    "    gdf_va = gqt.transform(gdf_va)\n",
    "    cdf_va = cqt.transform(cdf_va)\n",
    "    \n",
    "    print('PCA ',end='')\n",
    "    n_gpc, n_cpc = 80, 10\n",
    "    gpc = PCA(n_components=n_gpc, random_state=seed)\n",
    "    cpc = PCA(n_components=n_cpc, random_state=seed)\n",
    "    gdf_tr = gpc.fit_transform(gdf_tr)\n",
    "    cdf_tr = cpc.fit_transform(cdf_tr)\n",
    "    gdf_va = gpc.transform(gdf_va)\n",
    "    cdf_va = cpc.transform(cdf_va)\n",
    "    gcols_pca = [f'g-qpc{i}' for i in range(n_gpc)]\n",
    "    ccols_pca = [f'c-qpc{i}' for i in range(n_cpc)]\n",
    "    df_tr.loc[:, gcols_pca], df_tr.loc[:, ccols_pca] = gdf_tr, cdf_tr\n",
    "    df_va.loc[:, gcols_pca], df_va.loc[:, ccols_pca] = gdf_va, cdf_va\n",
    "    \n",
    "    \n",
    "    if drop:\n",
    "        print('DROP')\n",
    "        cols = gcols + ccols\n",
    "        print(df_tr.columns)\n",
    "        print(df_va.columns)\n",
    "        df_tr.drop(cols, axis=1, inplace=True)\n",
    "        df_va.drop(cols, axis=1, inplace=True)\n",
    "        cols_order = ['sig_id'] + gcols_pca + ccols_pca + targets + ['kfold'] + ['nsc_labels']\n",
    "    else:\n",
    "        cols_order = ['sig_id'] + gcols + ccols + gcols_pca + ccols_pca + targets + ['kfold'] + ['nsc_labels']\n",
    "    df_tr, df_va = df_tr[cols_order], df_va[cols_order]\n",
    "    return df_tr, df_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "      <th>nsc_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>-0.4047</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>-0.1321</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>-0.8789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>0.3055</td>\n",
       "      <td>-0.4726</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>-0.5565</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>-0.2541</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>-0.0340</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.4299</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>3.0790</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1088 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id     g-0     g-1     g-2     g-3     g-4     g-5     g-6  \\\n",
       "0      id_000644bb2  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120 -1.0220   \n",
       "1      id_000779bfc  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207  0.2341   \n",
       "2      id_000a6266a  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390  0.1715   \n",
       "3      id_0015fd391 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095 -1.9590   \n",
       "4      id_001626bd3 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244 -0.2800   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed  0.1394 -0.0636 -0.1112 -0.5080 -0.4713  0.7201  0.5773   \n",
       "23810  id_fffb70c0c -1.3260  0.3478 -0.3743  0.9905 -0.7178  0.6621 -0.2252   \n",
       "23811  id_fffc1c3f4  0.3942  0.3756  0.3109 -0.7389  0.5505 -0.0159 -0.2541   \n",
       "23812  id_fffcb9e7c  0.6660  0.2324  0.4392  0.2044  0.8531 -0.0343  0.0323   \n",
       "23813  id_ffffdd77b -0.8598  1.0240 -0.1361  0.7952 -0.3611 -3.6750 -1.2420   \n",
       "\n",
       "          g-7     g-8  ...  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0     -0.0326  0.5548  ...                0                  0   \n",
       "1      0.3372 -0.4047  ...                0                  0   \n",
       "2      0.2155  0.0065  ...                0                  0   \n",
       "3      0.1792 -0.1321  ...                0                  0   \n",
       "4     -0.1498 -0.8789  ...                0                  0   \n",
       "...       ...     ...  ...              ...                ...   \n",
       "23809  0.3055 -0.4726  ...                0                  0   \n",
       "23810 -0.5565  0.5112  ...                0                  0   \n",
       "23811  0.1745 -0.0340  ...                0                  0   \n",
       "23812  0.0463  0.4299  ...                0                  0   \n",
       "23813  0.9146  3.0790  ...                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                    0          0                           0              0   \n",
       "1                    0          0                           0              0   \n",
       "2                    0          0                           0              0   \n",
       "3                    0          0                           0              0   \n",
       "4                    0          0                           0              0   \n",
       "...                ...        ...                         ...            ...   \n",
       "23809                0          0                           0              0   \n",
       "23810                0          0                           0              0   \n",
       "23811                0          0                           0              0   \n",
       "23812                0          0                           0              0   \n",
       "23813                0          0                           0              0   \n",
       "\n",
       "       kfold  nsc_labels  \n",
       "0          4           0  \n",
       "1          2           0  \n",
       "2          4           0  \n",
       "3          0           0  \n",
       "4          1           0  \n",
       "...      ...         ...  \n",
       "23809      0           0  \n",
       "23810      4           0  \n",
       "23811      3           0  \n",
       "23812      4           0  \n",
       "23813      3           0  \n",
       "\n",
       "[23814 rows x 1088 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QT  PCA "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "      <th>nsc_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>-0.4047</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>-0.1321</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>-0.8789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>0.3055</td>\n",
       "      <td>-0.4726</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>-0.5565</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>-0.2541</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>-0.0340</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.4299</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>3.0790</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id     g-0     g-1     g-2     g-3     g-4     g-5     g-6  \\\n",
       "0      id_000644bb2  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120 -1.0220   \n",
       "1      id_000779bfc  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207  0.2341   \n",
       "2      id_000a6266a  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390  0.1715   \n",
       "3      id_0015fd391 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095 -1.9590   \n",
       "4      id_001626bd3 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244 -0.2800   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed  0.1394 -0.0636 -0.1112 -0.5080 -0.4713  0.7201  0.5773   \n",
       "23810  id_fffb70c0c -1.3260  0.3478 -0.3743  0.9905 -0.7178  0.6621 -0.2252   \n",
       "23811  id_fffc1c3f4  0.3942  0.3756  0.3109 -0.7389  0.5505 -0.0159 -0.2541   \n",
       "23812  id_fffcb9e7c  0.6660  0.2324  0.4392  0.2044  0.8531 -0.0343  0.0323   \n",
       "23813  id_ffffdd77b -0.8598  1.0240 -0.1361  0.7952 -0.3611 -3.6750 -1.2420   \n",
       "\n",
       "          g-7     g-8  ...  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0     -0.0326  0.5548  ...                0                  0   \n",
       "1      0.3372 -0.4047  ...                0                  0   \n",
       "2      0.2155  0.0065  ...                0                  0   \n",
       "3      0.1792 -0.1321  ...                0                  0   \n",
       "4     -0.1498 -0.8789  ...                0                  0   \n",
       "...       ...     ...  ...              ...                ...   \n",
       "23809  0.3055 -0.4726  ...                0                  0   \n",
       "23810 -0.5565  0.5112  ...                0                  0   \n",
       "23811  0.1745 -0.0340  ...                0                  0   \n",
       "23812  0.0463  0.4299  ...                0                  0   \n",
       "23813  0.9146  3.0790  ...                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \\\n",
       "0                    0          0                           0              0   \n",
       "1                    0          0                           0              0   \n",
       "2                    0          0                           0              0   \n",
       "3                    0          0                           0              0   \n",
       "4                    0          0                           0              0   \n",
       "...                ...        ...                         ...            ...   \n",
       "23809                0          0                           0              0   \n",
       "23810                0          0                           0              0   \n",
       "23811                0          0                           0              0   \n",
       "23812                0          0                           0              0   \n",
       "23813                0          0                           0              0   \n",
       "\n",
       "       kfold  nsc_labels  \n",
       "0          4           0  \n",
       "1          2           0  \n",
       "2          4           0  \n",
       "3          0           0  \n",
       "4          1           0  \n",
       "...      ...         ...  \n",
       "23809      0           0  \n",
       "23810      4           0  \n",
       "23811      3           0  \n",
       "23812      4           0  \n",
       "23813      3           0  \n",
       "\n",
       "[23814 rows x 1171 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/folds/train.csv\")\n",
    "display(df)\n",
    "df_tr, df_va = quantilePCA(df.copy(), df.copy(), drop=True)\n",
    "display(df_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: クラスタごとに並べてConv1d\n",
    "class BaseLine(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, num_layers=3, dropout=.2, hidden_size=256, activation=\"relu\", batchnorm=True, weight_norm=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.utils.weight_norm(nn.Linear(num_features if len(layers)==0 else hidden_size, hidden_size, bias=(not batchnorm))))\n",
    "            if batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            if activation == \"relu\":\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation == \"prelu\":\n",
    "                layers.append(nn.PReLU())\n",
    "            else:\n",
    "                raise RuntimeError(f'{activation} is not implemented')\n",
    "        # layers.append(nn.utils.weight_norm(nn.Linear(hidden_size, num_targets)))\n",
    "        layers.append(nn.Linear(hidden_size, num_targets))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_output_bias(model, df, targets):   \n",
    "    init_bias = np.array([])\n",
    "    for target in targets:\n",
    "        try:\n",
    "            neg, pos = np.bincount(df[target])\n",
    "        except ValueError:\n",
    "            neg, pos = np.array([df.shape[0], 0.01])\n",
    "        init_bias_ = np.log([pos/neg])\n",
    "        init_bias = np.append(init_bias, init_bias_)\n",
    "    model.model[-1].bias.data = torch.tensor(init_bias, dtype=torch.float32)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "    def forward(self, x, target, smoothing=0.2):\n",
    "        confidence = 1. - smoothing\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "from utils import LabelSmoothingCrossEntropy\n",
    "\n",
    "# criterion = LabelSmoothingCrossEntropy()\n",
    "# loss = criterion(outputs, targets)\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(df, fold, params, hp_tune=False):\n",
    "\n",
    "    save_model = False if hp_tune else True\n",
    "    print(f'\\n[Fold No.{fold:>3}]')\n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    train_df, valid_df = quantilePCA(train_df, valid_df, drop=True, seed=42)\n",
    "\n",
    "    x_tr = train_df[features].to_numpy()\n",
    "    x_va = valid_df[features].to_numpy()\n",
    "\n",
    "    y_tr = train_df[targets].to_numpy()\n",
    "    y_va = valid_df[targets].to_numpy()\n",
    "\n",
    "    dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "    loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=512, num_workers=2, pin_memory=True)\n",
    "    dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "    loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=512, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = BaseLine(num_features=x_tr.shape[1], num_targets=y_tr.shape[1], **params['nn_params'])\n",
    "    model = set_output_bias(model, train_df, targets)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    if params[\"optimizer\"] == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), **params[\"optim_params\"])\n",
    "    elif params[\"optimizer\"] == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), **params[\"optim_params\"])\n",
    "    elif params[\"optimizer\"] == \"AdamW\":\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), **params[\"optim_params\"])\n",
    "    elif params[\"optimizer\"] == \"AdaBelief\":\n",
    "        optimizer = AdaBelief(model.parameters(), **params[\"optim_params\"])\n",
    "    else:\n",
    "        raise RuntimeError(f'{params[\"optimizer\"]} is not implemented')\n",
    "\n",
    "    if params[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", **params[\"scdl_params\"])\n",
    "    elif params[\"scheduler\"] == \"CosineAnnealingLR\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **params[\"scdl_params\"])\n",
    "    elif params[\"scheduler\"] == \"none\": \n",
    "        print(\"No scheduling will be applied\")\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda ep: 1**ep)\n",
    "    else:\n",
    "        raise RuntimeError(f'{params[\"scheduler\"]} is not implemented')\n",
    "\n",
    "    eng = utils.Engine(model, optimizer, device=DEVICE)\n",
    "\n",
    "    del df, train_df, valid_df, x_tr, x_va, y_tr, y_va\n",
    "    gc.collect()\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    print(f'Training state is shown in {MODELNAME}/tensorboard')\n",
    "    filename = f\"{MODELNAME}/{now}_fold{fold}.pt\"\n",
    "\n",
    "    loss_best = np.inf\n",
    "    patience = 25\n",
    "    patience_cnt = 0\n",
    "    for ep in range(EPOCHS):\n",
    "        loss_tr = eng.train(loader_tr)\n",
    "        loss_tr_nodrop = eng.validate(loader_tr)\n",
    "        loss_va = eng.validate(loader_va)\n",
    "        scheduler.step(loss_va)\n",
    "        print(f'Ep.{ep:>3}/{EPOCHS:>3}, patience:{patience_cnt:>2}/{patience:>2}, train:{loss_tr:.6}, tr_nodrop:{loss_tr_nodrop:.6}, valid:{loss_va:.6}', end='\\r')\n",
    "        writer.add_scalars(f'{now}/fold{fold}', {'train':loss_tr, 'tr_nodrop':loss_tr_nodrop, 'valid':loss_va}, ep)\n",
    "        if loss_va < loss_best:\n",
    "            patience_cnt = 0\n",
    "            loss_best = loss_va\n",
    "            if save_model:\n",
    "                torch.save(model.model.state_dict(), filename)\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "        if patience_cnt > patience:\n",
    "            break\n",
    "\n",
    "    print(\"\\nmodel saved at:\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"nn_params\": {\"dropout\": 0.5, \"num_layers\":4, \"hidden_size\": 512, \"activation\": \"relu\", \"batchnorm\": True, \"weight_norm\": True},\n",
    "    \"optimizer\": \"Adam\",\n",
    "    # # SGD\n",
    "    # \"optim_params\": {\"lr\":1e-4, \"momentum\": 0.3, \"weight_decay\": 0.2, \"dampening\": 0, \"nesterov\": False},\n",
    "    # Adam\n",
    "    \"optim_params\": {\"lr\":1e-2, \"betas\": (0.9, 0.999), \"eps\": 1e-08, \"weight_decay\": 1.2e-6, \"amsgrad\": False},\n",
    "    # # Adabelief \n",
    "    # \"optim_params\": {\"lr\": 1e-2, \"eps\":1e-16, \"betas\": (0.9,0.999), \"weight_decay\": 1.2e-6, \"weight_decouple\": False, \"rectify\": True, \"fixed_decay\": False, \"amsgrad\": False},\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"scdl_params\": {\"threshold\": 1e-5, \"patience\": 3}\n",
    "    # # ReduceLROnPlateau\n",
    "    # \"scdl_params\": {\"threshold\": 1e-5, \"patience\": 3}\n",
    "    # # CosineAnnealingLR\n",
    "    # \"scdl_params\": {\"T_max\":8, \"eta_min\":0, \"last_epoch\":-1}\n",
    "}\n",
    "# 0.02355, 0.03 on momentum:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MODELNAME}/{now}_params.json', 'w') as f:\n",
    "    json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold No.  0]\n",
      "Training state is shown in Baseline1122/tensorboard\n",
      "Ep. 47/3000, patience:25/25, train:0.0148142, tr_nodrop:0.0140421, valid:0.0164846\n",
      "model saved at: Baseline1122/11-26_0045_fold0.pt\n",
      "\n",
      "[Fold No.  1]\n",
      "Training state is shown in Baseline1122/tensorboard\n",
      "Ep. 43/3000, patience:25/25, train:0.0147418, tr_nodrop:0.0139523, valid:0.0160776\n",
      "model saved at: Baseline1122/11-26_0045_fold1.pt\n",
      "\n",
      "[Fold No.  2]\n",
      "Training state is shown in Baseline1122/tensorboard\n",
      "Ep. 45/3000, patience:25/25, train:0.0144253, tr_nodrop:0.0136617, valid:0.0164775\n",
      "model saved at: Baseline1122/11-26_0045_fold2.pt\n",
      "\n",
      "[Fold No.  3]\n",
      "Training state is shown in Baseline1122/tensorboard\n",
      "Ep. 51/3000, patience:25/25, train:0.0144511, tr_nodrop:0.0136164, valid:0.0159169\n",
      "model saved at: Baseline1122/11-26_0045_fold3.pt\n",
      "\n",
      "[Fold No.  4]\n",
      "Training state is shown in Baseline1122/tensorboard\n",
      "Ep. 48/3000, patience:25/25, train:0.0145504, tr_nodrop:0.0138211, valid:0.0165258\n",
      "model saved at: Baseline1122/11-26_0045_fold4.pt\n",
      "Wall time: 33min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for fold in range(5):\n",
    "    run_training(df, fold, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Get CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold No.  4] Predicting...\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros((df.shape[0], len(targets)))\n",
    "for fold in range(5):\n",
    "    filename = f\"{MODELNAME}/{now}_fold{fold}.pt\"\n",
    "    print(f'[Fold No.{fold:>3}] Predicting...', end='\\r')\n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "    va_idx = df[df.kfold == fold].index\n",
    "    \n",
    "    x_tr = train_df[features].to_numpy()\n",
    "    x_va = valid_df[features].to_numpy()\n",
    "\n",
    "    y_tr = train_df[targets].to_numpy()\n",
    "    y_va = valid_df[targets].to_numpy()\n",
    "\n",
    "    dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "    loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=512, num_workers=2, pin_memory=True)\n",
    "    dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "    loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=512, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    model = BaseLine(num_features=x_tr.shape[1], num_targets=y_tr.shape[1], **params['nn_params'])\n",
    "    \n",
    "    weight = torch.load(filename, map_location=torch.device(DEVICE))\n",
    "    weight = OrderedDict([(f'model.{k}', v) for k, v in weight.items()])\n",
    "    model.load_state_dict(weight)\n",
    "    \n",
    "    model.eval()\n",
    "    ps = []\n",
    "    for ind, batch in enumerate(loader_va):\n",
    "        ps.append(torch.sigmoid(model(batch[\"x\"])).detach().cpu().numpy())\n",
    "    ps = np.vstack(ps)\n",
    "    predictions[va_idx] += ps\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score               : 0.016269\n"
     ]
    }
   ],
   "source": [
    "def log_loss_metric(y_true, y_pred):\n",
    "    y_pred_clip = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = - np.mean(np.mean(y_true * np.log(y_pred_clip) + (1 - y_true) * np.log(1 - y_pred_clip), axis = 1))\n",
    "    return loss\n",
    "print(f'CV score               : {log_loss_metric(df[targets].values, predictions):.6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "oof.iloc[:, 1:] = predictions\n",
    "oof.to_csv(f\"{MODELNAME}/oof.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score w/ postprocess: 0.0161582\n"
     ]
    }
   ],
   "source": [
    "predictions_ = predictions.copy()\n",
    "predictions_ = np.clip(predictions_,0.0005,0.999)\n",
    "predictions_[df[\"cp_type_ctl_vehicle\"]==1] = 0\n",
    "print(f'CV score w/ postprocess: {log_loss_metric(df[targets].values, predictions_):.6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score w/ postprocess: 0.0161582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'CV score w/ postprocess: {log_loss_metric(df[targets].values, predictions_):.6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: クラスタごとに並べてConv1d\n",
    "class BaseLine(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, num_layers=3, dropout=.2, hidden_size=256, activation=\"relu\", batchnorm=True, weight_norm=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.utils.weight_norm(nn.Linear(num_features if len(layers)==0 else hidden_size, hidden_size, bias=(not batchnorm))))\n",
    "            if batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            if activation == \"relu\":\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation == \"prelu\":\n",
    "                layers.append(nn.PReLU())\n",
    "            else:\n",
    "                raise RuntimeError(f'{activation} is not implemented')\n",
    "        # layers.append(nn.utils.weight_norm(nn.Linear(hidden_size, num_targets)))\n",
    "        layers.append(nn.Linear(hidden_size, num_targets))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/folds/train.csv\")\n",
    "with open(\"../input/folds/targets\", \"r\") as f:\n",
    "    targets = f.read().split(\"\\n\")[:-1]\n",
    "with open(\"../input/folds/features\", \"r\") as f:\n",
    "    features = f.read().split(\"\\n\")\n",
    "with open(PARAMS_PATH) as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_metric(y_true, y_pred):\n",
    "    y_pred_clip = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = - np.mean(np.mean(y_true * np.log(y_pred_clip) + (1 - y_true) * np.log(1 - y_pred_clip), axis = 1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predicting as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold No.  4] Predicting...\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros((df.shape[0], len(targets)))\n",
    "for fold in range(5):\n",
    "    print(f'[Fold No.{fold:>3}] Predicting...', end='\\r')\n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "    va_idx = df[df.kfold == fold].index\n",
    "    \n",
    "    x_tr = train_df[features].to_numpy()\n",
    "    x_va = valid_df[features].to_numpy()\n",
    "\n",
    "    y_tr = train_df[targets].to_numpy()\n",
    "    y_va = valid_df[targets].to_numpy()\n",
    "\n",
    "    dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "    loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=512, num_workers=2, pin_memory=True)\n",
    "    dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "    loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=512, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    model = BaseLine(num_features=x_tr.shape[1], num_targets=y_tr.shape[1], **params['nn_params'])\n",
    "    \n",
    "    weight = torch.load(WEIGHT_PATHS[fold], map_location=torch.device(DEVICE))\n",
    "    weight = OrderedDict([(f'model.{k}', v) for k, v in weight.items()])\n",
    "    model.load_state_dict(weight)\n",
    "    \n",
    "    model.eval()\n",
    "    ps = []\n",
    "    for ind, batch in enumerate(loader_va):\n",
    "        ps.append(torch.sigmoid(model(batch[\"x\"])).detach().cpu().numpy())\n",
    "    ps = np.vstack(ps)\n",
    "    predictions[va_idx] += ps\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score               : 0.016269\n",
      "CV score w/ postprocess: 0.0161582\n"
     ]
    }
   ],
   "source": [
    "print(f'CV score               : {log_loss_metric(df[targets].values, predictions):.6}')\n",
    "predictions_ = predictions.copy()\n",
    "predictions_ = np.clip(predictions_,0.0005,0.999)\n",
    "predictions_[df[\"cp_type_ctl_vehicle\"]==1] = 0\n",
    "print(f'CV score w/ postprocess: {log_loss_metric(df[targets].values, predictions_):.6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting w/ dropout ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRIAL No.   0] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   1] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   2] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   3] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   4] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   5] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   6] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   7] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   8] [Fold No.  4] Predicting...\n",
      "[TRIAL No.   9] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  10] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  11] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  12] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  13] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  14] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  15] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  16] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  17] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  18] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  19] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  20] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  21] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  22] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  23] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  24] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  25] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  26] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  27] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  28] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  29] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  30] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  31] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  32] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  33] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  34] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  35] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  36] [Fold No.  4] Predicting...\n",
      "[TRIAL No.  37] [Fold No.  2] Predicting...\r"
     ]
    }
   ],
   "source": [
    "sg = nn.Sigmoid()\n",
    "N_TRIALS = 100\n",
    "predictions = np.zeros((df.shape[0], len(targets)))\n",
    "for seed in range(N_TRIALS):\n",
    "    for fold in range(5):\n",
    "        print(f'[TRIAL No. {seed:>3}] [Fold No.{fold:>3}] Predicting...', end='\\r')\n",
    "        train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "        valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "        va_idx = df[df.kfold == fold].index\n",
    "\n",
    "        x_tr = train_df[features].to_numpy()\n",
    "        x_va = valid_df[features].to_numpy()\n",
    "\n",
    "        y_tr = train_df[targets].to_numpy()\n",
    "        y_va = valid_df[targets].to_numpy()\n",
    "\n",
    "        dataset_tr = utils.MoaDataset(x_tr, y_tr)\n",
    "        loader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=512, num_workers=2, pin_memory=True)\n",
    "        dataset_va = utils.MoaDataset(x_va, y_va)\n",
    "        loader_va = torch.utils.data.DataLoader(dataset_va, batch_size=512, num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = BaseLine(num_features=x_tr.shape[1], num_targets=y_tr.shape[1], **params['nn_params'])\n",
    "\n",
    "        weight = torch.load(WEIGHT_PATHS[fold], map_location=torch.device(DEVICE))\n",
    "        weight = OrderedDict([(f'model.{k}', v) for k, v in weight.items()])\n",
    "        model.load_state_dict(weight)\n",
    "\n",
    "        model.train()\n",
    "        ps = []\n",
    "        for ind, batch in enumerate(loader_va):\n",
    "            ps.append(torch.sigmoid(model(batch[\"x\"])).detach().cpu().numpy())\n",
    "        ps = np.vstack(ps)\n",
    "        predictions[va_idx] += ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score               : 0.0163489\n",
      "CV score w/ postprocess: 0.0162451\n"
     ]
    }
   ],
   "source": [
    "print(f'CV score               : {log_loss_metric(df[targets].values, predictions):.6}')\n",
    "predictions_ = predictions.copy()\n",
    "predictions_ = np.clip(predictions_,0.0005,0.999)\n",
    "predictions_[df[\"cp_type_ctl_vehicle\"]==1] = 0\n",
    "print(f'CV score w/ postprocess: {log_loss_metric(df[targets].values, predictions_):.6}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
